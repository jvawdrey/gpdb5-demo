{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Workflow Example - Greenplum Database\n",
    "\n",
    "----\n",
    "\n",
    "Greenplum Database features used\n",
    "\n",
    "* Apache MADlib - http://madlib.apache.org/\n",
    "* Procedural language extension to Python - https://gpdb.docs.pivotal.io/530/ref_guide/extensions/pl_python.html\n",
    "\n",
    "----\n",
    "\n",
    "### Example Description\n",
    "\n",
    "**Use case:**\n",
    "\n",
    "Using available credit card application data build a classification model to predict whether or not a new application will be approved.\n",
    "\n",
    "**Data:** \n",
    "\n",
    "Credit Approval Data Set found at UCI Machine Learning Repository\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
    "\n",
    "----\n",
    "\n",
    "## Index\n",
    "\n",
    "### Setup \n",
    "\n",
    "* <a href=\"#dependencies\">Dependencies</a>\n",
    "* <a href=\"#package_options\">Package Options</a>\n",
    "* <a href=\"#database_connection\">Database Connection</a>\n",
    "    \n",
    "    \n",
    "### Data Loading\n",
    "\n",
    "* <a href=\"#external_table\">External Table Definition</a>\n",
    "* <a href=\"#download_data\">Download Data</a>\n",
    "* <a href=\"#view_sample\">View Sample</a>\n",
    "\n",
    "\n",
    "### Data Audit\n",
    "\n",
    "* <a href=\"#summary_statistics\">Summary Statistics</a>\n",
    "\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "* <a href=\"#de_categorical\">Categorical Columns</a>\n",
    "* <a href=\"#de_continuous\">Continuous Columns</a>\n",
    "\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "* <a href=\"#fe_continuous\">Continuous Features</a>\n",
    "* <a href=\"#fe_one_hot\">One Hot Encode Categorical Features</a>\n",
    "* <a href=\"#fe_combine\">Combine Continuous & Categorical Features</a>\n",
    "* <a href=\"#fe_cats_dep\">Plot Categorical Features By Response</a>\n",
    "* <a href=\"#fe_chi_sq\">Chi-squared Testing</a>\n",
    "* <a href=\"#fe_corr\">Correlation Testing</a>\n",
    "* <a href=\"#fe_scatter\">Scatter Plots</a>\n",
    "\n",
    "\n",
    "### Model Development\n",
    "\n",
    "* <a href=\"#train_vali_split\">Training & Validation Sample Split</a>\n",
    "\n",
    "\n",
    "* **Random Forest (MADlib)**\n",
    "    * <a href=\"#rf_train_model\">Train model</a>\n",
    "    * <a href=\"#rf_variable_importance\">Variable Importance</a>\n",
    "    * <a href=\"#rf_score_out_of_sample\">Score Validation Data</a>\n",
    "    * <a href=\"#rf_auc\">Area Under ROC Curve</a>\n",
    "    * <a href=\"#rf_roc\">Receiver Operating Characteristic Graph (ROC Curve)</a>\n",
    "    * <a href=\"#rf_confusion_matrix\">Confusion Matrix</a>\n",
    "    \n",
    "    \n",
    "* **XGBoost (PL/Python)**\n",
    "    * <a href=\"#xg_load_plpython_udf\">Load PL/Python UDF</a>\n",
    "    * <a href=\"#xg_train_model\">Train model</a>\n",
    "    * <a href=\"#xg_score_out_of_sample\">Score Validation Data</a>\n",
    "    * <a href=\"#xg_auc\">Area Under ROC Curve</a>\n",
    "    * <a href=\"#xg_roc\">Receiver Operating Characteristic Graph (ROC Curve)</a>\n",
    "    * <a href=\"#xg_confusion_matrix\">Confusion Matrix</a>\n",
    "\n",
    "### Model Scoring\n",
    "\n",
    "\n",
    "* <a href=\"#model_scoring_Example\">Model Scoring Example</a>\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dependencies\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import psycopg2               # Python-PostgreSQL Database Adapter - https://pypi.python.org/pypi/psycopg2\n",
    "import pandas as pd           # Python Data Analysis Library - https://pandas.pydata.org/\n",
    "import seaborn as sns         # Statistical data visualization - https://seaborn.pydata.org/\n",
    "import math                   # Mathematical functions - https://docs.python.org/2/library/math.html\n",
    "import textwrap as tw         # Text wrapping and filling - https://docs.python.org/2/library/textwrap.html\n",
    "import ipywidgets as widgets  # Jupyter Widgets - https://ipywidgets.readthedocs.io/en/latest/\n",
    "import IPython.display as ipd # http://ipython.org/documentation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"package_options\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# package options\n",
    "# %matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    \n",
    "pd.options.mode.chained_assignment = None \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 10000\n",
    "\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"database_connection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Connection Details \n",
       " ------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Host:** gpdb (default)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Database name:** gpadmin (default)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Username:** gpadmin (default)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Password:** pivotal (default)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "------"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:green'>**Connection successful!**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init to default values\n",
    "database_host = 'gpdb'\n",
    "database_databasename = 'gpadmin'\n",
    "database_username = 'gpadmin'\n",
    "database_password = 'pivotal'\n",
    "\n",
    "# interpret string as markdown\n",
    "def printmd(string):\n",
    "    ipd.display(ipd.Markdown(string))\n",
    "    \n",
    "# forms\n",
    "message = \"### Connection Details \\n ------\"\n",
    "printmd(message)\n",
    "    \n",
    "printmd(\"**Host:**\")\n",
    "inputHost = widgets.Text()\n",
    "ipd.display(inputHost)\n",
    "\n",
    "printmd(\"**Database Name:**\")\n",
    "inputDatabaseName = widgets.Text()\n",
    "ipd.display(inputDatabaseName)\n",
    "\n",
    "printmd(\"**Username:**\")\n",
    "inputUsername = widgets.Text()\n",
    "ipd.display(inputUsername)\n",
    "\n",
    "printmd(\"**Password:**\")\n",
    "inputPassword = widgets.Text()\n",
    "ipd.display(inputPassword)\n",
    "\n",
    "printmd(\"*Leave blank for default values*\")\n",
    "\n",
    "\n",
    "def db_connect():\n",
    "    global conn, cur\n",
    "    try:\n",
    "        conn = psycopg2.connect(\"host='{}' dbname='{}' user='{}' password='{}'\".format(database_host,database_databasename,database_username,database_password))\n",
    "        cur = conn.cursor()\n",
    "        conn.autocommit = True\n",
    "        message = \"<span style='color:green'>**Connection successful!**</span>\"\n",
    "        printmd(message)\n",
    "    except:\n",
    "        message = \"<span style='color:red'>**ERROR: Unable to connect to the database**</span>\"\n",
    "        printmd(message)\n",
    "    \n",
    "def on_button_click(b):\n",
    "    \n",
    "    global database_host, database_databasename, database_username, database_password\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Connection Details \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    if inputHost.value == \"\":\n",
    "        message = \"**Host:** {} (default)\".format(database_host)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_host = inputHost.value\n",
    "        message = \"**Host:** {}\".format(database_host)\n",
    "        printmd(message)\n",
    "  \n",
    "    if inputDatabaseName.value == \"\":\n",
    "        message = \"**Database name:** {} (default)\".format(database_databasename)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_databasename = inputDatabaseName.value\n",
    "        message = \"**Database name:** {}\".format(database_databasename)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputUsername.value == \"\":\n",
    "        message = \"**Username:** {} (default)\".format(database_username)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_username = inputUsername.value\n",
    "        message = \"**Username:** {}\".format(database_username)\n",
    "        printmd(message)\n",
    "        \n",
    "    if inputPassword.value == \"\":\n",
    "        message = \"**Password:** {} (default)\".format(database_password)\n",
    "        printmd(message)\n",
    "    else:\n",
    "        database_password = inputPassword.value\n",
    "        message = \"**Password:** ###########\"\n",
    "        printmd(message)\n",
    "    \n",
    "    printmd(\"------\")\n",
    "    db_connect()\n",
    "        \n",
    "button = widgets.Button(description=\"Connect\")\n",
    "ipd.display(button)\n",
    "button.on_click(on_button_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"external_table\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create external web table\n",
    "ddl = \"\"\"\n",
    "    DROP EXTERNAL TABLE IF EXISTS public.credit_application_external;\n",
    "    CREATE EXTERNAL WEB TABLE public.credit_application_external (\n",
    "        a1 varchar(1)\n",
    "       ,a2 float\n",
    "       ,a3 float\n",
    "       ,a4 varchar(1)\n",
    "       ,a5 varchar(2)\n",
    "       ,a6 varchar(2)\n",
    "       ,a7 varchar(2)\n",
    "       ,a8 float\n",
    "       ,a9 boolean\n",
    "       ,a10 boolean\n",
    "       ,a11 float\n",
    "       ,a12 boolean\n",
    "       ,a13 varchar(1)\n",
    "       ,a14 float\n",
    "       ,a15 float\n",
    "       ,a16 varchar(1)\n",
    "    ) LOCATION ('http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data')\n",
    "    FORMAT 'CSV'\n",
    "    (NULL AS '?');\n",
    "\"\"\"\n",
    "cur.execute(ddl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute mean or most freq occuring value for null \n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.credit_application_data;\n",
    "    CREATE TABLE public.credit_application_data AS\n",
    "    SELECT row_number() OVER() AS _id\n",
    "          ,coalesce(a1,'b') AS a1\n",
    "          ,coalesce(a2, avg(a2) OVER()) AS a2\n",
    "          ,coalesce(a3, avg(a3) OVER()) AS a3\n",
    "          ,coalesce(a4, 'u') AS a4\n",
    "          ,coalesce(a5, 'g') AS a5\n",
    "          ,coalesce(a6, 'c') AS a6\n",
    "          ,coalesce(a7, 'v') AS a7\n",
    "          ,coalesce(a8, avg(a8) OVER()) AS a8\n",
    "          ,coalesce(a9, True) AS a9\n",
    "          ,coalesce(a10, False) AS a10\n",
    "          ,coalesce(a11, 0) AS a11\n",
    "          ,coalesce(a12, False) AS a12\n",
    "          ,coalesce(a13, 'g') AS a13\n",
    "          ,coalesce(a14, avg(a14) OVER()) AS a14\n",
    "          ,coalesce(a15, avg(a15) OVER()) AS a15\n",
    "          ,CASE WHEN a16 = '+' THEN 1 ELSE 0 END AS a16\n",
    "    FROM public.credit_application_external\n",
    "    DISTRIBUTED RANDOMLY;\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"view_sample\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function\n",
    "def query_gpdb(query): \n",
    "\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>a7</th>\n",
       "      <th>a8</th>\n",
       "      <th>a9</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>r</td>\n",
       "      <td>h</td>\n",
       "      <td>6.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>g</td>\n",
       "      <td>164.0</td>\n",
       "      <td>31285.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>b</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>h</td>\n",
       "      <td>3.96</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>g</td>\n",
       "      <td>180.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id a1     a2     a3 a4 a5 a6 a7    a8    a9    a10  a11    a12 a13    a14  \\\n",
       "0  1    b  30.83  0.000  u  g  w  v  1.25  True  True   1.0  False  g   202.0   \n",
       "1  3    a  24.50  0.500  u  g  q  h  1.50  True  False  0.0  False  g   280.0   \n",
       "2  5    b  20.17  5.625  u  g  w  v  1.71  True  False  0.0  False  s   120.0   \n",
       "3  7    b  33.17  1.040  u  g  r  h  6.50  True  False  0.0  True   g   164.0   \n",
       "4  9    b  54.42  0.500  y  p  k  h  3.96  True  False  0.0  False  g   180.0   \n",
       "\n",
       "       a15  a16  \n",
       "0  0.0      1    \n",
       "1  824.0    1    \n",
       "2  0.0      1    \n",
       "3  31285.0  1    \n",
       "4  314.0    1    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view sample\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.credit_application_data\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary_statistics\"></a>\n",
    "Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop existing table & run madlib summary stats function\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.credit_application_summary;\n",
    "    SELECT madlib.summary('public.credit_application_data','public.credit_application_summary');\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "# grab results from gpdb\n",
    "query = \"\"\"\n",
    "    SELECT * FROM public.credit_application_summary;\n",
    "\"\"\"\n",
    "data_summary = query_gpdb(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_by</th>\n",
       "      <th>group_by_value</th>\n",
       "      <th>target_column</th>\n",
       "      <th>column_number</th>\n",
       "      <th>data_type</th>\n",
       "      <th>row_count</th>\n",
       "      <th>distinct_values</th>\n",
       "      <th>missing_values</th>\n",
       "      <th>blank_values</th>\n",
       "      <th>fraction_missing</th>\n",
       "      <th>fraction_blank</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>first_quartile</th>\n",
       "      <th>median</th>\n",
       "      <th>third_quartile</th>\n",
       "      <th>most_frequent_values</th>\n",
       "      <th>mfv_frequencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>_id</td>\n",
       "      <td>1</td>\n",
       "      <td>int8</td>\n",
       "      <td>690</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>345.500000</td>\n",
       "      <td>3.973250e+04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>690.00</td>\n",
       "      <td>173.250</td>\n",
       "      <td>345.500</td>\n",
       "      <td>517.7500</td>\n",
       "      <td>[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a1</td>\n",
       "      <td>2</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[b, b, a, a]</td>\n",
       "      <td>[480, 480, 210, 210]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a2</td>\n",
       "      <td>3</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.568171</td>\n",
       "      <td>1.405001e+02</td>\n",
       "      <td>13.75</td>\n",
       "      <td>80.25</td>\n",
       "      <td>22.670</td>\n",
       "      <td>28.625</td>\n",
       "      <td>37.7075</td>\n",
       "      <td>[31.5681710914455, 31.5681710914455, 22.67, 22.67, 20.42, 18.83, 25, 24.5, 19.17, 20.67]</td>\n",
       "      <td>[12, 12, 9, 9, 7, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a3</td>\n",
       "      <td>4</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.478211e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.750</td>\n",
       "      <td>7.2075</td>\n",
       "      <td>[1.5, 0, 3, 2.5, 0, 2.5, 3, 1.25, 1.25, 0.75]</td>\n",
       "      <td>[21, 19, 19, 19, 19, 19, 19, 16, 16, 16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a4</td>\n",
       "      <td>5</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[u, u, y, y, l]</td>\n",
       "      <td>[525, 525, 163, 163, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a5</td>\n",
       "      <td>6</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[g, g, p, p, gg]</td>\n",
       "      <td>[525, 525, 163, 163, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a6</td>\n",
       "      <td>7</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[c, c, q, q, w, w, i, i, aa, aa]</td>\n",
       "      <td>[146, 146, 78, 78, 64, 64, 59, 59, 54, 54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a7</td>\n",
       "      <td>8</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[v, v, h, h, bb, bb, ff, ff, j, z]</td>\n",
       "      <td>[408, 408, 138, 138, 59, 59, 57, 57, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a8</td>\n",
       "      <td>9</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>1.119915e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.50</td>\n",
       "      <td>0.165</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>[0, 0, 0.25, 0.25, 0.04, 0.04, 1, 1, 0.125, 0.125]</td>\n",
       "      <td>[70, 70, 35, 35, 33, 33, 31, 31, 30, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a9</td>\n",
       "      <td>10</td>\n",
       "      <td>bool</td>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[t, t, f, f]</td>\n",
       "      <td>[361, 361, 329, 329]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a10</td>\n",
       "      <td>11</td>\n",
       "      <td>bool</td>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[f, f, t, t]</td>\n",
       "      <td>[395, 395, 295, 295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a11</td>\n",
       "      <td>12</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.364819e+01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>[0, 0, 1, 1, 2, 2, 3, 3, 6, 6]</td>\n",
       "      <td>[395, 395, 71, 71, 45, 45, 28, 28, 23, 23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a12</td>\n",
       "      <td>13</td>\n",
       "      <td>bool</td>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[f, f, t, t]</td>\n",
       "      <td>[374, 374, 316, 316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a13</td>\n",
       "      <td>14</td>\n",
       "      <td>varchar</td>\n",
       "      <td>690</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[g, g, s, s, p, p]</td>\n",
       "      <td>[625, 625, 57, 57, 8, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a14</td>\n",
       "      <td>15</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>184.014771</td>\n",
       "      <td>2.963882e+04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>80.000</td>\n",
       "      <td>160.000</td>\n",
       "      <td>272.0000</td>\n",
       "      <td>[0, 0, 200, 120, 200, 120, 160, 160, 80, 100]</td>\n",
       "      <td>[132, 132, 35, 35, 35, 35, 34, 34, 30, 30]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a15</td>\n",
       "      <td>16</td>\n",
       "      <td>float8</td>\n",
       "      <td>690</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017.385507</td>\n",
       "      <td>2.714517e+07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100000.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>395.5000</td>\n",
       "      <td>[0, 0, 1, 1, 500, 1000, 500, 1000, 2, 2]</td>\n",
       "      <td>[295, 295, 29, 29, 10, 10, 10, 10, 9, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>a16</td>\n",
       "      <td>17</td>\n",
       "      <td>int4</td>\n",
       "      <td>690</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444928</td>\n",
       "      <td>2.473255e-01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>[0, 0, 1, 1]</td>\n",
       "      <td>[383, 383, 307, 307]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_by group_by_value target_column  column_number data_type  row_count  \\\n",
       "0   None     None           _id           1              int8      690         \n",
       "1   None     None           a1            2              varchar   690         \n",
       "2   None     None           a2            3              float8    690         \n",
       "3   None     None           a3            4              float8    690         \n",
       "4   None     None           a4            5              varchar   690         \n",
       "5   None     None           a5            6              varchar   690         \n",
       "6   None     None           a6            7              varchar   690         \n",
       "7   None     None           a7            8              varchar   690         \n",
       "8   None     None           a8            9              float8    690         \n",
       "9   None     None           a9            10             bool      690         \n",
       "10  None     None           a10           11             bool      690         \n",
       "11  None     None           a11           12             float8    690         \n",
       "12  None     None           a12           13             bool      690         \n",
       "13  None     None           a13           14             varchar   690         \n",
       "14  None     None           a14           15             float8    690         \n",
       "15  None     None           a15           16             float8    690         \n",
       "16  None     None           a16           17             int4      690         \n",
       "\n",
       "    distinct_values  missing_values  blank_values  fraction_missing  \\\n",
       "0   690              0              NaN            0.0                \n",
       "1   2                0               0.0           0.0                \n",
       "2   350              0              NaN            0.0                \n",
       "3   215              0              NaN            0.0                \n",
       "4   3                0               0.0           0.0                \n",
       "5   3                0               0.0           0.0                \n",
       "6   14               0               0.0           0.0                \n",
       "7   9                0               0.0           0.0                \n",
       "8   132              0              NaN            0.0                \n",
       "9   2                0              NaN            0.0                \n",
       "10  2                0              NaN            0.0                \n",
       "11  23               0              NaN            0.0                \n",
       "12  2                0              NaN            0.0                \n",
       "13  3                0               0.0           0.0                \n",
       "14  171              0              NaN            0.0                \n",
       "15  240              0              NaN            0.0                \n",
       "16  2                0              NaN            0.0                \n",
       "\n",
       "    fraction_blank         mean      variance    min        max  \\\n",
       "0  NaN              345.500000   3.973250e+04  1.00   690.00      \n",
       "1   0.0            NaN          NaN            1.00   1.00        \n",
       "2  NaN              31.568171    1.405001e+02  13.75  80.25       \n",
       "3  NaN              4.758725     2.478211e+01  0.00   28.00       \n",
       "4   0.0            NaN          NaN            1.00   1.00        \n",
       "5   0.0            NaN          NaN            1.00   2.00        \n",
       "6   0.0            NaN          NaN            1.00   2.00        \n",
       "7   0.0            NaN          NaN            1.00   2.00        \n",
       "8  NaN              2.223406     1.119915e+01  0.00   28.50       \n",
       "9  NaN             NaN          NaN           NaN    NaN          \n",
       "10 NaN             NaN          NaN           NaN    NaN          \n",
       "11 NaN              2.400000     2.364819e+01  0.00   67.00       \n",
       "12 NaN             NaN          NaN           NaN    NaN          \n",
       "13  0.0            NaN          NaN            1.00   1.00        \n",
       "14 NaN              184.014771   2.963882e+04  0.00   2000.00     \n",
       "15 NaN              1017.385507  2.714517e+07  0.00   100000.00   \n",
       "16 NaN              0.444928     2.473255e-01  0.00   1.00        \n",
       "\n",
       "    first_quartile   median  third_quartile  \\\n",
       "0   173.250         345.500  517.7500         \n",
       "1  NaN             NaN      NaN               \n",
       "2   22.670          28.625   37.7075          \n",
       "3   1.000           2.750    7.2075           \n",
       "4  NaN             NaN      NaN               \n",
       "5  NaN             NaN      NaN               \n",
       "6  NaN             NaN      NaN               \n",
       "7  NaN             NaN      NaN               \n",
       "8   0.165           1.000    2.6250           \n",
       "9  NaN             NaN      NaN               \n",
       "10 NaN             NaN      NaN               \n",
       "11  0.000           0.000    3.0000           \n",
       "12 NaN             NaN      NaN               \n",
       "13 NaN             NaN      NaN               \n",
       "14  80.000          160.000  272.0000         \n",
       "15  0.000           5.000    395.5000         \n",
       "16  0.000           0.000    1.0000           \n",
       "\n",
       "                                                                        most_frequent_values  \\\n",
       "0   [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]                                                        \n",
       "1   [b, b, a, a]                                                                               \n",
       "2   [31.5681710914455, 31.5681710914455, 22.67, 22.67, 20.42, 18.83, 25, 24.5, 19.17, 20.67]   \n",
       "3   [1.5, 0, 3, 2.5, 0, 2.5, 3, 1.25, 1.25, 0.75]                                              \n",
       "4   [u, u, y, y, l]                                                                            \n",
       "5   [g, g, p, p, gg]                                                                           \n",
       "6   [c, c, q, q, w, w, i, i, aa, aa]                                                           \n",
       "7   [v, v, h, h, bb, bb, ff, ff, j, z]                                                         \n",
       "8   [0, 0, 0.25, 0.25, 0.04, 0.04, 1, 1, 0.125, 0.125]                                         \n",
       "9   [t, t, f, f]                                                                               \n",
       "10  [f, f, t, t]                                                                               \n",
       "11  [0, 0, 1, 1, 2, 2, 3, 3, 6, 6]                                                             \n",
       "12  [f, f, t, t]                                                                               \n",
       "13  [g, g, s, s, p, p]                                                                         \n",
       "14  [0, 0, 200, 120, 200, 120, 160, 160, 80, 100]                                              \n",
       "15  [0, 0, 1, 1, 500, 1000, 500, 1000, 2, 2]                                                   \n",
       "16  [0, 0, 1, 1]                                                                               \n",
       "\n",
       "                               mfv_frequencies  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]              \n",
       "1   [480, 480, 210, 210]                        \n",
       "2   [12, 12, 9, 9, 7, 6, 6, 6, 6, 6]            \n",
       "3   [21, 19, 19, 19, 19, 19, 19, 16, 16, 16]    \n",
       "4   [525, 525, 163, 163, 2]                     \n",
       "5   [525, 525, 163, 163, 2]                     \n",
       "6   [146, 146, 78, 78, 64, 64, 59, 59, 54, 54]  \n",
       "7   [408, 408, 138, 138, 59, 59, 57, 57, 8, 8]  \n",
       "8   [70, 70, 35, 35, 33, 33, 31, 31, 30, 30]    \n",
       "9   [361, 361, 329, 329]                        \n",
       "10  [395, 395, 295, 295]                        \n",
       "11  [395, 395, 71, 71, 45, 45, 28, 28, 23, 23]  \n",
       "12  [374, 374, 316, 316]                        \n",
       "13  [625, 625, 57, 57, 8, 8]                    \n",
       "14  [132, 132, 35, 35, 35, 35, 34, 34, 30, 30]  \n",
       "15  [295, 295, 29, 29, 10, 10, 10, 10, 9, 9]    \n",
       "16  [383, 383, 307, 307]                        "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de_categorical\"></a>\n",
    "#### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n",
       " **Select Column:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a15fecbeb8459d9fadba4d2c09f789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAIACAYAAACraVuzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQENAAAFBDQAABQQ0AAAUEBAAwBAgf8H9Z0DzTS2ftcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd24546e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "catColumns = ['a1','a4','a5','a6','a7','a9','a10','a12','a13','a16']\n",
    "\n",
    "def bar_plot(data,title,x,xLabel,y,yLabel,color=None,xAxisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=12)\n",
    "    plt.set_ylabel(yLabel,fontsize=12)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(xAxisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "\n",
    "def get_cat_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.credit_application_data\n",
    "            GROUP BY 1\n",
    "        ) foo\n",
    "        ORDER BY perc_records DESC\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catDropdown)\n",
    "        df = get_cat_data_frame(res['new'])\n",
    "        bar_plot(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Records\", None, 0)\n",
    "    \n",
    "catDropdown = widgets.Dropdown(\n",
    "    options=catColumns,\n",
    "    value=catColumns[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catDropdown.observe(on_cat_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catDropdown)\n",
    "df = get_cat_data_frame(catColumns[0])\n",
    "bar_plot(df,catColumns[0],\"col\",catColumns[0],\"perc_records\",\"% Records\", None, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"de_continuous\"></a>\n",
    "#### Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530a6b7226134dc7979c8126f865ac36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-----\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAI6CAYAAADsVGQBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncDgcDofTQfw/BkU9NusC88kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd0098f110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contColumns = ['a2','a3','a8','a11','a14','a15']\n",
    "sliderValue = 20\n",
    "colName = contColumns[0]\n",
    "\n",
    "def get_cont_data_frame(col, buckets):\n",
    "    query = \"\"\"\n",
    "        WITH aggs AS (\n",
    "            SELECT min({c}) AS min,\n",
    "                   max({c}) AS max\n",
    "              FROM public.credit_application_data\n",
    "        )\n",
    "        SELECT width_bucket({c}, min, max, {b}-1) AS bucket,\n",
    "               ('[' || min({c}) || ',' || max({c}) || ')')::text as range,\n",
    "               count(*) as freq\n",
    "        FROM public.credit_application_data, aggs\n",
    "        GROUP BY bucket\n",
    "        ORDER BY bucket\n",
    "    \"\"\".format(c=col, b=buckets)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def graph_reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n\")\n",
    "    ipd.display(widgets.HBox((contDropdown,bucketsSlider)))\n",
    "    printmd(\"-----\\n\")\n",
    "    df = get_cont_data_frame(colName,sliderValue)\n",
    "    bar_plot(df,colName,\"range\",colName,\"freq\",\"Frequency\", \"#4378E2\")    \n",
    "    \n",
    "def on_cont_selection(res):\n",
    "    global colName\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        colName = res['new']\n",
    "        graph_reset()\n",
    "        \n",
    "def on_slider_selection(res):\n",
    "    global sliderValue\n",
    "    if res['new'] == {} and res['old']:\n",
    "        sliderValue = res['old']['value']\n",
    "        graph_reset()\n",
    "    \n",
    "# Look at log transforms\n",
    "# colsAddLogs = contColumns + [\"log({} + 1)\".format(c) for c in contColumns]\n",
    "colsAddLogs = contColumns\n",
    "\n",
    "contDropdown = widgets.Dropdown(\n",
    "    options=colsAddLogs,\n",
    "    value=colsAddLogs[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "bucketsSlider = widgets.IntSlider(\n",
    "    value=sliderValue,\n",
    "    min=5,\n",
    "    max=50,\n",
    "    step=1,\n",
    "    description='# Buckets:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "contDropdown.observe(on_cont_selection)\n",
    "bucketsSlider.observe(on_slider_selection)\n",
    "\n",
    "graph_reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a15 large number of outliers - consider correcting\n",
    "* Consider variable transformation if test non-tree based algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_continuous\"></a>\n",
    "#### Continuous Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>approval</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a8</th>\n",
       "      <th>a11</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>39.830000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>27.250000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>31.568171</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>12.750</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  approval         a2      a3     a8  a11    a14  a15\n",
       "0  83   0         39.830000  0.500   0.250  0.0  288.0  0.0\n",
       "1  85   0         27.250000  0.625   0.455  0.0  200.0  0.0\n",
       "2  87   0         31.568171  0.375   0.875  0.0  928.0  0.0\n",
       "3  89   0         34.000000  4.500   1.000  0.0  240.0  0.0\n",
       "4  91   0         62.500000  12.750  5.000  0.0  112.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continuos features (seperated out incase feature transformations are required)\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cont;\n",
    "    CREATE TABLE public.model_inputs_cont AS\n",
    "    SELECT _id\n",
    "          ,a16 AS approval\n",
    "          ,a2\n",
    "          ,a3\n",
    "          ,a8\n",
    "          ,a11\n",
    "          ,a14\n",
    "          ,a15\n",
    "    FROM public.credit_application_data\n",
    "    DISTRIBUTED BY (_id);\n",
    "    SELECT * FROM public.model_inputs_cont LIMIT 0;\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "contFeatureNames = [desc[0] for desc in cur.description]\n",
    "contFeatureNames.remove('_id')\n",
    "contFeatureNames.remove('approval')\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cont\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "print len(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_one_hot\"></a>\n",
    "#### One Hot Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a2', 'a3', 'a8', 'a11', 'a14', 'a15', 'a1_a', 'a4_l', 'a4_u', 'a5_g', 'a5_gg', 'a6_aa', 'a6_c', 'a6_cc', 'a6_d', 'a6_e', 'a6_ff', 'a6_i', 'a6_j', 'a6_k', 'a6_m', 'a6_q', 'a6_r', 'a6_w', 'a7_bb', 'a7_dd', 'a7_ff', 'a7_h', 'a7_j', 'a7_n', 'a7_o', 'a7_v', 'a9_true', 'a10_true', 'a12_true', 'a13_g', 'a13_p']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>a1_a</th>\n",
       "      <th>a4_l</th>\n",
       "      <th>a4_u</th>\n",
       "      <th>a5_g</th>\n",
       "      <th>a5_gg</th>\n",
       "      <th>a6_aa</th>\n",
       "      <th>a6_c</th>\n",
       "      <th>a6_cc</th>\n",
       "      <th>a6_d</th>\n",
       "      <th>a6_e</th>\n",
       "      <th>a6_ff</th>\n",
       "      <th>a6_i</th>\n",
       "      <th>a6_j</th>\n",
       "      <th>a6_k</th>\n",
       "      <th>a6_m</th>\n",
       "      <th>a6_q</th>\n",
       "      <th>a6_r</th>\n",
       "      <th>a6_w</th>\n",
       "      <th>a7_bb</th>\n",
       "      <th>a7_dd</th>\n",
       "      <th>a7_ff</th>\n",
       "      <th>a7_h</th>\n",
       "      <th>a7_j</th>\n",
       "      <th>a7_n</th>\n",
       "      <th>a7_o</th>\n",
       "      <th>a7_v</th>\n",
       "      <th>a9_true</th>\n",
       "      <th>a10_true</th>\n",
       "      <th>a12_true</th>\n",
       "      <th>a13_g</th>\n",
       "      <th>a13_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  a1_a  a4_l  a4_u  a5_g  a5_gg  a6_aa  a6_c  a6_cc  a6_d  a6_e  a6_ff  \\\n",
       "0  83   0     0     1     1     0      0      0     0      0     0     0       \n",
       "1  85   0     0     1     1     0      1      0     0      0     0     0       \n",
       "2  87   0     0     1     1     0      0      0     0      1     0     0       \n",
       "3  89   0     0     1     1     0      1      0     0      0     0     0       \n",
       "4  91   0     0     0     0     0      0      1     0      0     0     0       \n",
       "\n",
       "   a6_i  a6_j  a6_k  a6_m  a6_q  a6_r  a6_w  a7_bb  a7_dd  a7_ff  a7_h  a7_j  \\\n",
       "0  0     0     0     1     0     0     0     0      0      0      0     0      \n",
       "1  0     0     0     0     0     0     0     0      0      0      0     0      \n",
       "2  0     0     0     0     0     0     0     0      0      0      0     0      \n",
       "3  0     0     0     0     0     0     0     0      0      0      0     0      \n",
       "4  0     0     0     0     0     0     0     0      0      0      1     0      \n",
       "\n",
       "   a7_n  a7_o  a7_v  a9_true  a10_true  a12_true  a13_g  a13_p  \n",
       "0  0     0     1     1        0         0         0      0      \n",
       "1  0     0     1     1        0         1         1      0      \n",
       "2  0     0     1     1        0         1         0      0      \n",
       "3  0     0     1     1        0         1         1      0      \n",
       "4  0     0     0     1        0         0         1      0      "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode categorical features\n",
    "# https://madlib.apache.org/docs/latest/group__grp__encode__categorical.html\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs_cat;\n",
    "    SELECT madlib.encode_categorical_variables (\n",
    "        'public.credit_application_data',\n",
    "        'public.model_inputs_cat',\n",
    "        'a1,a4,a5,a6,a7,a9,a10,a12,a13',\n",
    "        NULL,\n",
    "        '_id',\n",
    "        NULL,\n",
    "        'a1=b, a4=y, a5=p, a6=x, a7=z, a9=False, a10=False, a12=False, a13=s'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    ALTER TABLE public.model_inputs_cat RENAME COLUMN \"a9_True\" TO a9_true;\n",
    "    ALTER TABLE public.model_inputs_cat RENAME COLUMN \"a10_True\" TO a10_true;\n",
    "    ALTER TABLE public.model_inputs_cat RENAME COLUMN \"a12_True\" TO a12_true;\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "colnames = [desc[0] for desc in cur.description]\n",
    "df = pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "colnames.remove('_id')\n",
    "catFeatureNames = colnames\n",
    "featureNames = contFeatureNames + catFeatureNames\n",
    "print featureNames\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_combine\"></a>\n",
    "#### Combine Continuous & Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine feature tables\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_inputs;\n",
    "    CREATE TABLE public.model_inputs AS\n",
    "    SELECT *\n",
    "    FROM public.model_inputs_cat\n",
    "    JOIN public.model_inputs_cont\n",
    "    USING (_id);\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_cats_dep\"></a>\n",
    "#### Plot Categorical Features By Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n",
       " **Select Column:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212bb29b7c0a41838df519d79aadd808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtIAAAH+CAYAAACx7Ol6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd000e1110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bar_plot_groupby(data, title,x,xLabel,y,yLabel,groupby,color=None,axisRotation=90):\n",
    "\n",
    "    # Bar plot\n",
    "    pylab.rcParams['figure.figsize'] = (12, 8)\n",
    "    seq_col_brew = sns.color_palette(\"Blues_r\", 1)\n",
    "    sns.color_palette(seq_col_brew)\n",
    "    if color != None:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, color=color, hue=groupby)\n",
    "    else:\n",
    "        plt = sns.barplot(x=x, y=y, data=data, hue=groupby)\n",
    "        \n",
    "    # titles\n",
    "    plt.set_title(title,fontsize=30)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "    \n",
    "    # rotate x axis labels\n",
    "    for item in plt.get_xticklabels():\n",
    "        item.set_rotation(axisRotation)\n",
    "\n",
    "    # remove scientific notation\n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "def get_cat_gb_data_frame(col):\n",
    "    query = \"\"\"\n",
    "        SELECT *\n",
    "              ,round((record_count * 100.0) / sum(record_count) OVER(PARTITION BY col),2) AS perc_records\n",
    "        FROM (\n",
    "            SELECT {} AS col\n",
    "                  ,approval\n",
    "                  ,count(*) AS record_count\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        ) foo\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(col)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    \n",
    "def on_cat_gb_selection(res):\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        ipd.clear_output()\n",
    "        printmd(\"-----\\n **Select Column:**\")\n",
    "        ipd.display(catGPDropdown)\n",
    "        df = get_cat_gb_data_frame(res['new'])\n",
    "        bar_plot_groupby(df,res['new'],\"col\",res['new'],\"perc_records\",\"% Class Records\", \"approval\")\n",
    "    \n",
    "catGPDropdown = widgets.Dropdown(\n",
    "    options=catFeatureNames,\n",
    "    value=catFeatureNames[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "catGPDropdown.observe(on_cat_gb_selection)\n",
    "printmd(\"-----\\n **Select Column:**\")\n",
    "ipd.display(catGPDropdown)\n",
    "df = get_cat_gb_data_frame(catFeatureNames[0])\n",
    "bar_plot_groupby(df,catFeatureNames[0],\"col\",catFeatureNames[0],\"perc_records\",\"% Class Records\",\"approval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_chi_sq\"></a>\n",
    "#### Chi-squared testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>response</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "      <th>df</th>\n",
       "      <th>phi</th>\n",
       "      <th>contingency_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_o</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.024633</td>\n",
       "      <td>8.752845e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078475</td>\n",
       "      <td>0.078234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_c</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.038090</td>\n",
       "      <td>8.452629e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097583</td>\n",
       "      <td>0.097122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_n</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.049410</td>\n",
       "      <td>8.240931e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111142</td>\n",
       "      <td>0.110462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_m</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.092817</td>\n",
       "      <td>7.606255e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152330</td>\n",
       "      <td>0.150593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_bb</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.117396</td>\n",
       "      <td>7.318764e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171315</td>\n",
       "      <td>0.168855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_j</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.160255</td>\n",
       "      <td>6.889216e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200159</td>\n",
       "      <td>0.196266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_dd</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.305203</td>\n",
       "      <td>5.806390e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.276226</td>\n",
       "      <td>0.266255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1_a</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.577660</td>\n",
       "      <td>4.472309e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.380020</td>\n",
       "      <td>0.355234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_r</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.599873</td>\n",
       "      <td>4.386265e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.387257</td>\n",
       "      <td>0.361124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a12_true</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.690089</td>\n",
       "      <td>4.061341e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415358</td>\n",
       "      <td>0.383585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_j</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.862985</td>\n",
       "      <td>3.529048e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464485</td>\n",
       "      <td>0.421260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a13_p</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.062699</td>\n",
       "      <td>3.026004e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515437</td>\n",
       "      <td>0.458157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_e</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.390821</td>\n",
       "      <td>2.382665e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.589665</td>\n",
       "      <td>0.507935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_w</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.427656</td>\n",
       "      <td>2.321474e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.597423</td>\n",
       "      <td>0.512868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_v</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.767027</td>\n",
       "      <td>1.837504e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.664648</td>\n",
       "      <td>0.553536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4_l</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.388196</td>\n",
       "      <td>2.387099e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680244</td>\n",
       "      <td>0.562448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a5_gg</td>\n",
       "      <td>approval</td>\n",
       "      <td>1.388196</td>\n",
       "      <td>2.387099e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.680244</td>\n",
       "      <td>0.562448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_aa</td>\n",
       "      <td>approval</td>\n",
       "      <td>2.055035</td>\n",
       "      <td>1.517038e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.716770</td>\n",
       "      <td>0.582574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a13_g</td>\n",
       "      <td>approval</td>\n",
       "      <td>5.472360</td>\n",
       "      <td>1.931952e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.169654</td>\n",
       "      <td>0.760078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_d</td>\n",
       "      <td>approval</td>\n",
       "      <td>5.685844</td>\n",
       "      <td>1.710231e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.192250</td>\n",
       "      <td>0.766176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_k</td>\n",
       "      <td>approval</td>\n",
       "      <td>6.476032</td>\n",
       "      <td>1.093388e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.272402</td>\n",
       "      <td>0.786242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_i</td>\n",
       "      <td>approval</td>\n",
       "      <td>11.262954</td>\n",
       "      <td>7.906928e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.678016</td>\n",
       "      <td>0.859027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_cc</td>\n",
       "      <td>approval</td>\n",
       "      <td>12.151847</td>\n",
       "      <td>4.903926e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.742975</td>\n",
       "      <td>0.867381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_q</td>\n",
       "      <td>approval</td>\n",
       "      <td>15.542025</td>\n",
       "      <td>8.069134e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.971169</td>\n",
       "      <td>0.891803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a5_g</td>\n",
       "      <td>approval</td>\n",
       "      <td>22.501101</td>\n",
       "      <td>2.100232e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.371766</td>\n",
       "      <td>0.921446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a4_u</td>\n",
       "      <td>approval</td>\n",
       "      <td>22.501101</td>\n",
       "      <td>2.100232e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.371766</td>\n",
       "      <td>0.921446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6_ff</td>\n",
       "      <td>approval</td>\n",
       "      <td>22.752264</td>\n",
       "      <td>1.842869e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.384967</td>\n",
       "      <td>0.922215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_ff</td>\n",
       "      <td>approval</td>\n",
       "      <td>23.338584</td>\n",
       "      <td>1.358474e-06</td>\n",
       "      <td>1</td>\n",
       "      <td>2.415501</td>\n",
       "      <td>0.923952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a7_h</td>\n",
       "      <td>approval</td>\n",
       "      <td>24.036537</td>\n",
       "      <td>9.452489e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>2.451354</td>\n",
       "      <td>0.925921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a10_true</td>\n",
       "      <td>approval</td>\n",
       "      <td>144.927676</td>\n",
       "      <td>2.227269e-33</td>\n",
       "      <td>1</td>\n",
       "      <td>6.019296</td>\n",
       "      <td>0.986479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a9_true</td>\n",
       "      <td>approval</td>\n",
       "      <td>358.100326</td>\n",
       "      <td>7.298530e-80</td>\n",
       "      <td>1</td>\n",
       "      <td>9.461769</td>\n",
       "      <td>0.994461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_name  response   statistic       p_value  df       phi  \\\n",
       "0  a7_o         approval  0.024633    8.752845e-01  1   0.078475   \n",
       "0  a6_c         approval  0.038090    8.452629e-01  1   0.097583   \n",
       "0  a7_n         approval  0.049410    8.240931e-01  1   0.111142   \n",
       "0  a6_m         approval  0.092817    7.606255e-01  1   0.152330   \n",
       "0  a7_bb        approval  0.117396    7.318764e-01  1   0.171315   \n",
       "0  a7_j         approval  0.160255    6.889216e-01  1   0.200159   \n",
       "0  a7_dd        approval  0.305203    5.806390e-01  1   0.276226   \n",
       "0  a1_a         approval  0.577660    4.472309e-01  1   0.380020   \n",
       "0  a6_r         approval  0.599873    4.386265e-01  1   0.387257   \n",
       "0  a12_true     approval  0.690089    4.061341e-01  1   0.415358   \n",
       "0  a6_j         approval  0.862985    3.529048e-01  1   0.464485   \n",
       "0  a13_p        approval  1.062699    3.026004e-01  1   0.515437   \n",
       "0  a6_e         approval  1.390821    2.382665e-01  1   0.589665   \n",
       "0  a6_w         approval  1.427656    2.321474e-01  1   0.597423   \n",
       "0  a7_v         approval  1.767027    1.837504e-01  1   0.664648   \n",
       "0  a4_l         approval  1.388196    2.387099e-01  1   0.680244   \n",
       "0  a5_gg        approval  1.388196    2.387099e-01  1   0.680244   \n",
       "0  a6_aa        approval  2.055035    1.517038e-01  1   0.716770   \n",
       "0  a13_g        approval  5.472360    1.931952e-02  1   1.169654   \n",
       "0  a6_d         approval  5.685844    1.710231e-02  1   1.192250   \n",
       "0  a6_k         approval  6.476032    1.093388e-02  1   1.272402   \n",
       "0  a6_i         approval  11.262954   7.906928e-04  1   1.678016   \n",
       "0  a6_cc        approval  12.151847   4.903926e-04  1   1.742975   \n",
       "0  a6_q         approval  15.542025   8.069134e-05  1   1.971169   \n",
       "0  a5_g         approval  22.501101   2.100232e-06  1   2.371766   \n",
       "0  a4_u         approval  22.501101   2.100232e-06  1   2.371766   \n",
       "0  a6_ff        approval  22.752264   1.842869e-06  1   2.384967   \n",
       "0  a7_ff        approval  23.338584   1.358474e-06  1   2.415501   \n",
       "0  a7_h         approval  24.036537   9.452489e-07  1   2.451354   \n",
       "0  a10_true     approval  144.927676  2.227269e-33  1   6.019296   \n",
       "0  a9_true      approval  358.100326  7.298530e-80  1   9.461769   \n",
       "\n",
       "   contingency_coef  \n",
       "0  0.078234          \n",
       "0  0.097122          \n",
       "0  0.110462          \n",
       "0  0.150593          \n",
       "0  0.168855          \n",
       "0  0.196266          \n",
       "0  0.266255          \n",
       "0  0.355234          \n",
       "0  0.361124          \n",
       "0  0.383585          \n",
       "0  0.421260          \n",
       "0  0.458157          \n",
       "0  0.507935          \n",
       "0  0.512868          \n",
       "0  0.553536          \n",
       "0  0.562448          \n",
       "0  0.562448          \n",
       "0  0.582574          \n",
       "0  0.760078          \n",
       "0  0.766176          \n",
       "0  0.786242          \n",
       "0  0.859027          \n",
       "0  0.867381          \n",
       "0  0.891803          \n",
       "0  0.921446          \n",
       "0  0.921446          \n",
       "0  0.922215          \n",
       "0  0.923952          \n",
       "0  0.925921          \n",
       "0  0.986479          \n",
       "0  0.994461          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAIiCAYAAADRge6vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIIcLBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd000e7050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def chi2_gof_test(feature_name, response):\n",
    "    query = \"\"\"\n",
    "        WITH freq AS (\n",
    "            SELECT {feature_name}\n",
    "                  ,{response}\n",
    "                  ,count(*) AS observed\n",
    "            FROM public.model_inputs\n",
    "            GROUP BY 1,2\n",
    "        )\n",
    "        SELECT '{feature_name}' AS feature_name\n",
    "              ,'{response}' AS response\n",
    "              ,(madlib.chi2_gof_test(observed, expected, deg_freedom)).*\n",
    "        FROM (\n",
    "            SELECT observed\n",
    "                  ,sum(observed) OVER (PARTITION BY {feature_name})::DOUBLE PRECISION\n",
    "                       * sum(observed) OVER (PARTITION BY {response}) AS expected\n",
    "            FROM freq\n",
    "        ) l, (\n",
    "            SELECT (count(distinct {feature_name}) - 1) * (count(distinct {response}) - 1) AS deg_freedom\n",
    "            FROM freq\n",
    "        ) r;\n",
    "    \"\"\".format(feature_name=feature_name, response=response)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    return pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "\n",
    "def chi2_gof_test_multi(feature_list, response):\n",
    "    res = chi2_gof_test(feature_list[0], response)\n",
    "    for i in range(1,len(feature_list)):\n",
    "        res = res.append(chi2_gof_test(feature_list[i], response))\n",
    "        \n",
    "    return res\n",
    "\n",
    "chi2_results = chi2_gof_test_multi(catFeatureNames, 'approval')\n",
    "chi2_results.sort_values('phi', inplace=True)\n",
    "ipd.display(chi2_results)\n",
    "bar_plot(chi2_results, \"Chi-Squared Testing\",\"feature_name\",\"Feature Name\",\"phi\",\"Test Statistic\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_corr\"></a>\n",
    "#### Correlation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a8</th>\n",
       "      <th>a11</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a3</th>\n",
       "      <td>0.201316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a8</th>\n",
       "      <td>0.392787</td>\n",
       "      <td>0.298902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a11</th>\n",
       "      <td>0.185575</td>\n",
       "      <td>0.271207</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a14</th>\n",
       "      <td>-0.077161</td>\n",
       "      <td>-0.222346</td>\n",
       "      <td>-0.076389</td>\n",
       "      <td>-0.119809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a15</th>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.123121</td>\n",
       "      <td>0.051345</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>0.065609</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                a2        a3        a8       a11       a14  a15\n",
       "variable                                                       \n",
       "a2        1.000000 NaN       NaN       NaN       NaN       NaN \n",
       "a3        0.201316  1.000000 NaN       NaN       NaN       NaN \n",
       "a8        0.392787  0.298902  1.000000 NaN       NaN       NaN \n",
       "a11       0.185575  0.271207  0.322330  1.000000 NaN       NaN \n",
       "a14      -0.077161 -0.222346 -0.076389 -0.119809  1.000000 NaN \n",
       "a15       0.018539  0.123121  0.051345  0.063692  0.065609  1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc correlations\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.feature_correlations, public.feature_correlations_summary;\n",
    "    SELECT madlib.correlation( \n",
    "        'public.model_inputs',\n",
    "        'public.feature_correlations',\n",
    "        '{}'\n",
    "    );\n",
    "    SELECT * \n",
    "    FROM public.feature_correlations\n",
    "    ORDER BY column_position;\n",
    "\"\"\".format(\",\".join(contFeatureNames))\n",
    "corr = query_gpdb(query)\n",
    "\n",
    "corr.drop('column_position', 'columns', inplace=True)\n",
    "corr.set_index('variable', True, False, True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fccf50c8510>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAAIICAYAAADJzFLnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xd4VFXixvF3UiaNBAikUIMEEJRo\nVKQsJRhKREBAcO0KK2JF8LfrWlaxw2JnFUXEFQJWAlERURSQJhZwBVQsQBJqCiW9TDIzvz8iA3GC\nJCb3JjN8P88zz5O598yc4kjenHPmXovT6XQKAAAApvFp6AYAAACcbghgAAAAJiOAAQAAmIwABgAA\nYDICGAAAgMkIYAAAACbza+gG/JGcnIKGboJHi4gIZQzrAeNYdxERoZL4f7qu+CzWHZ/F+nFsHPHn\nMQMGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEAAJiMAAYAAGAy\nAhgAAIDJCGAAAAAmI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkI\nYAAAACYjgAEAAJiMAAYAAGAyAhgAAIDJCGAAAAAmI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOA\nAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEAAJiMAAYAAGAyAhgAAIDJCGAAAAAmI4ABAACYjAAG\nAABgMgIYAACAyQwLYOvXr9fixYu1b9++KsdTUlKMqhIAAMAjGBLAnn32Wc2ZM0e//PKLxo8fr4UL\nF7rOvfHGG0ZUCQAA4DH8jHjTNWvWKDU1VX5+fpo8ebL+/ve/a+/evbr//vvldDqNqBIAAMBjGDID\nVlFRIT+/ymwXFhamOXPmqLCwUHfeeafKy8uNqBIAAMBjGBLA2rdvr6+//tr13NfXV9OnT9cZZ5yh\n3bt3G1ElAACAxzBkCXLWrFmun/Py8pSRkaGysjL169dPsbGxRlQJAADgMQwJYIGBgZKkxYsXKzk5\nWZmZmeratau2bt2q+Ph4XXrppUZUCwAA4BEMvQ5YcnKyUlJS1Lp1ay1cuFCpqakKDw83skoAAIBG\nz9AAZrVaFRAQIEmy2WyKjY1VWlqakVUCAAA0eoYsQR4THR2t/Px8DR48WBMmTFBYWJgiIyONrBIA\nAKDRMzSAzZ49W5I0efJk9erVSwUFBerfv7+RVQIAADR6hgawE/Xs2dOsqgAAABo1bsYNAABgMgIY\nAACAyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEAAJiMAAYAAGAyAhgAAIDJCGAA\nAAAmI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEA\nAJiMAAYAAGAyAhgAAIDJCGAAAAAmI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAA\nYDKL0+l0NnQjAAAATifMgAEAAJjMr6Eb8EcO3PNQQzfBo7We+YhycgoauhkeLyIilHGso4iIUEli\nHOuIz2Ld8VmsH8fGEX8eM2AAAAAmI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAA\nYDICGAAAgMkIYAAAACYjgAEAAJiMAAYAAGAyAhgAAIDJCGAAAAAmI4ABAACYjAAGAABgMgIYAACA\nyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEAAJiMAAYAAGAyAhgAAIDJCGAAAAAm\nI4ABAACYjAAGAABgMgIYAACAyQhgAAAAJiOAAQAAmIwABgAAYDICGAAAgMkIYAAAACYjgAEAAJjM\nr6Eb0JhZgoLUbNwoBXSJlaOoWAUff6aS77a7lQsZ0FfBF5wr3+bN5CgqVtGmb1S0bmMDtBgAAHgC\nAtgfaDp6uGS3K+uxp+TfOlrhE65R+cFMVWTlVClnsUi576SqPDNLvuHN1WLi9bLn5al06/cN1HIA\nANCYsQR5EhZ/fwV176b8lavltNlkS9+j0h9/VtB557qVLVy7UeUHDkoOh+yHDqv0x59kjWnfAK0G\nAAC1tW7dOiUlJWnIkCGaO3eu2/m33npLI0eO1KhRo3TVVVdp586dda6TAHYSvhEtJKdT9kOHXcfK\nD2bKPyrylK8N6BCjiqxsI5sHAADqgd1u16OPPqp58+Zp+fLl+vDDD90C1siRI7Vs2TK9//77mjhx\nombMmFHneg0JYE6nUx999JFWrFghp9OpTZs26fHHH9cbb7whh8NhRJX1zsdqlaO0tMoxZ2mZLAHW\nP3xd6JCLJItFxZv/Z2TzAABAPdi2bZtiYmLUrl07Wa1WDR8+XKtWrapSpkmTJq6fS0pKZLFY6lyv\nIXvAHnnkER05ckQ2m02rVq2SzWZTYmKi1q5dq7S0ND3wwANGVFuvHDabLAEBVY5ZAgLkLLOd9DXB\nfXoq6PxzdWjOfyW73egmAgBw2vm1X1Ktynfe8Mkfns/KylJ0dLTreVRUlLZt2+ZW7o033tDrr7+u\n8vJyLViwoFZtqI4hAWzLli1atmyZysvL1a9fP61fv15Wq1UjRozQmDFjjKiy3tlzDsvi4yPfFuGy\nHz4iSfJvFaXykywtBvU4T6EX9dOhOa/LkZdvZlMBAMCf5HQ63Y5VN8N1zTXX6JprrtGyZcv08ssv\na+bMmXWq15AlSF9fX0mSv7+/unfvLqu1ctnOz89PPj6ese3MWV6u0h92KHRooiz+/rLGtFPg2V1V\n8r+tbmWD4uMUdvEgHZ6XLPuRow3QWgAAThMWn9o9TiE6OlqZmZmu51lZWYqMPPl+7+HDh+uzzz6r\nczcMSUMtW7ZUUVGRJOm1115zHc/JyZG/v78RVRoiN3W5LP5+ipr2TzW7epzyUj9URVaOrB3aK/rR\n+13lQpMGySc4WC3vmKToR+9X9KP3q+mYEQ3YcgAAvJTFUrvHKcTFxSk9PV179+6VzWbT8uXLlZiY\nWKVMenq66+fPP/9cMTExde6GIUuQ8+bNc/2cl5enjIwMlZWVqbi4WDfeeKMRVRrCWVKio8lvux23\npe9R5rTprufZM583s1kAAJy2LD513wB/Ij8/P02bNk0TJ06U3W7X2LFj1blzZ82aNUvdu3fXoEGD\ntGjRIm3atEl+fn4KCwur8/KjZPCFWBcvXqzk5GRlZmaqa9eu2rp1q+Lj4zVs2DAjqwUAAN6qBsuK\ntZWQkKCEhIQqx6ZMmeL62YgvDxq6ISs5OVkpKSlq3bq1Fi5cqNTUVIWHhxtZJQAA8Gb1vATZUAyd\nAbNarQr47VIONptNsbGxSktLM7JKAADgzep5CbKhGBrAoqOjlZ+fr8GDB2vChAkKCwv7w28WAAAA\nnA4MDWCzZ8+WJE2ePFm9evVSQUGB+vfvb2SVAADAi9XHVegbA0MD2Il69uxpVlUAAMBbecj1RE/F\ntAAGAABQZ8yAAQAAmIwABgAAYC4LS5AAAAAmI4ABAACYzEuWIL0jRgIAAHgQZsAAAIDH4DpgAAAA\nZuNWRAAAACbz9W3oFtQLAhgAAPAYLEECAACYzeId3x8kgAEAAM/hJXvAvCNGAgAAeBBmwAAAgMfg\nVkQAAABmYxM+AACAyQhgAAAAJmMJEgAAwFxcBwwAAMBsXnIZCgIYAADwHF5yIVbv6AUAAIAHYQYM\nAAB4DvaAAQAAmMvCHjAAAACTMQMGAABgMq4DBgAAYC7uBQkAAGA2liABAABM5iUBzDvm8QAAADyI\nxel0Ohu6EQAAADWx7857alW+7X9mGtSSumnUS5C/9ktq6CZ4tM4bPmEM60HnDZ8oJ6egoZvh0SIi\nQiWJcayjiIhQxrCO+CzWj2Pj2BDYhA8AAGA2L7kQq3fESAAAcHqw+NTuUQPr1q1TUlKShgwZorlz\n57qdf/3113XJJZdo5MiRuuGGG7R///46d4MABgAAPIbFx1Krx6nY7XY9+uijmjdvnpYvX64PP/xQ\nO3furFKmW7duWrJkiZYtW6akpCQ99dRTde4HAQwAAHgOH5/aPU5h27ZtiomJUbt27WS1WjV8+HCt\nWrWqSpnevXsrKChIkhQfH6/MzMy6d6PO7wAAAOChsrKyFB0d7XoeFRWlrKysk5ZPSUnRgAED6lwv\nm/ABAIDnqOcLsVZ3NS7LSep4//339f3332vRokV1rpcABgAAPMbJwtGfFR0dXWVJMSsrS5GRkW7l\nvvjiC82ZM0eLFi2S1Wqtc70sQQIAAM9Rz3vA4uLilJ6err1798pms2n58uVKTEysUubHH3/UtGnT\n9PLLL6tFixb10g1mwAAAgOeo5xkwPz8/TZs2TRMnTpTdbtfYsWPVuXNnzZo1S927d9egQYP05JNP\nqri4WFOmTJEktWrVSnPmzKlbvfXReAAAAFMYcDPuhIQEJSQkVDl2LGxJ0vz58+u9TgIYAADwGNyK\nCAAAwGwGzIA1BO+IkQAAAB6EGTAAAOA5vORm3AQwAADgObxkCZIABgAAPAab8AEAAMxmIYABAACY\niz1gAAAA5qrve0E2FAIYAADwHCxBAgAAmIwlSAAAAJOxBAkAAGAuCzNgAAAAJmMPGAAAgMlYggQA\nADAZS5AAAADm8pZbEXlHLwAAADwIM2AAAMBzsAkfAADAZOwBAwAAMBf3ggQAADAbAQwAAMBkXvIt\nSAIYAADwHMyAAQAAmIs9YF7IJzRUUffdpeALL5A9L0+HX3ldBZ+ucSvX7PIxanb5KPk0DZOzpFQF\nq9bq0EuvSnaHJCmw+1mKuPMWWTu0U/mBTGU/+6JKt/1gdncajfoaVwAAvAUB7ASRf79dzvIK7b70\nCgV0jlXrJx9T2c7dsqVlVClXtPFL5a9YKUdhkXxCQ9Xq8QfUbNxo5b6zVD6hoWr974eV/cwLKly7\nUaGDB6r1zEeU/tfxchQUNlDPGlZ9jCsAAJK8Zg+Yd/SiHlgCA9QkoZ8Oz1sgZ0mpSrf9oKINmxSa\nNMitbPmBg3IUFv32QklOp/zbtpYkBcWdpYqjuSpcs15yOFSwcrXsuXlqMqCvib1pPOprXAEAkFS5\nB6w2j0bKkBmw3NxcLVq0SFFRURo3bpzmzJmj7777Th07dtQtt9yipk2bGlFtnVjbtZXT4VD53v2u\nY2W70hQUH1dt+dAhFyniH5PlGxKiiqO5ynlxbuWJav9bW2Tt2KHe2+wJ6m1cAQCQmAH7I3fffbdK\nSkr0/fff6/rrr9ehQ4d00003KTAwUPfee68RVdaZJSjo+OzLbxyFRfIJDqq2fMGna7Q76TKlXzlB\nee8vl/3IUUlSyfYf5deyhZoMHij5+ir04sHyb9NKPoEBRnehUaqvcQUAQJIsPpZaPRorQwJYdna2\n7r77bj388MNKT0/Xgw8+qB49emjKlCk6cOCAEVXWmbOkRD4hwVWO+YQEy1Fc8oevK993QLa0DEX+\n/Q5JkiO/QAfve1jNr7hMHZe9o5DePVS8+X+qyD5kWNsbs/oaVwAAJLEE+UccDofy8vJUVFSk4uJi\n7du3T23bttXRo0dVXl5uRJV1Ztu7TxZfX/m3ba3yfZUhMaBTR7eN4tWx+PrKv83xvUol323X3pvu\nrHzi66MO78xX7ttLDGl3Y1ef4woAgLfcjNuQXtx8880aNmyYxo0bp+nTp+uBBx7QhAkTdOmll+qG\nG24woso6c5aWqXDtRrWYeL0sgQEKjDtLIf36qOCTVW5lw0ZcLN9mlfvYrB3aq/l1V6p48/9c5wM6\nx0q+vvIJDlbL2yepIvuQir/eYlpfGpP6HFcAALxlCdKQGbARI0Zo2LBhcjqdKioqUosWLbR161aN\nGzdOkZGRRlRZL7KfeVFR9/2fOi57V/b8fOU884JsaRkKPKe72jz9uHYNHS1JCoo7Wy0mjZdPUJDs\nuZXfeDw8b4HrfZpfc7mCe/eUJBV/tVkH73+kQfrTWNTXuAIA0JiXFWvD4nQ6nUa9+eLFi5WcnKzM\nzEx17dpVW7duVXx8vJKTk2v0+l/7JRnVtNNC5w2fMIb1oPOGT5STU9DQzfBoERGhksQ41lFERChj\nWEd8FuvHsXFsCLmL369V+WaXjzKoJXVj6EJqcnKyUlJS1Lp1ay1cuFCpqakKDw83skoAAODNfCy1\nezRShl4J32q1KiCg8vILNptNsbGxSktLM7JKAADgxbgXZA1ER0crPz9fgwcP1oQJExQWFtao94AB\nAIBGrhHPatWGoUuQs2fPVlhYmCZPnqwpU6Zo3Lhxmj17tpFVAgAAb+bjU7tHDaxbt05JSUkaMmSI\n5s51vwPLN998ozFjxuiss87Sxx9/XC/dMO1m3D179jSrKgAA4K3q+Tpgdrtdjz76qF5//XXXLRQT\nExPVqVMnV5lWrVppxowZ+u9//1tv9ZoWwAAAABqbbdu2KSYmRu3atZMkDR8+XKtWraoSwNq2bStJ\n8qnH+1B6x+VkAQDAacFisdTqcSpZWVmKjo52PY+KilJWVpaRXZDEDBgAAPAk9bwJv7rLoZrxTUsC\nGAAA8Bz1HI6io6OVmZnpep6VlWXKFRtYggQAAJ7D4lO7xynExcUpPT1de/fulc1m0/Lly5WYmGh4\nNwhgAADAY9T3zbj9/Pw0bdo0TZw4UZdccomGDRumzp07a9asWVq1apWkyo36AwYM0Mcff6yHHnpI\nw4cPr3M/WIIEAACew4D9WQkJCUpISKhybMqUKa6fzznnHK1bt65e6ySAAQAAz1GPl4JoSN7RCwAA\nAA/CDBgAAPAY3nIz7lrNgB05csSodgAAAJyaAfeCbAg1atnWrVt10UUXacyYMZKk7du368EHHzS0\nYQAAAG4slto9GqkaBbAZM2bo1VdfVfPmzSVVXjPj22+/NbRhAAAAbnwstXs0UjXaA1ZeXl7lppSS\n5O/vb0iDAAAATsbi49vQTagXNQpgVqtVRUVFro1vO3fuVEBAgKENAwAAcNOIZ7Vqo0YB7JZbbtGN\nN96o7Oxs3XvvvVq/fr2eeuopo9sGAADglWoUwBISEtSxY0etX79eTqdTt956q2JiYoxuGwAAQFU1\nuL+jJ6jxdcDatWunq6++2si2AAAA/KGa3N/RE/xhABs7duwfXvAsJSWl3hsEAABwUo340hK18YcB\n7J577jGrHQAAAKd2OgSwnj17VnleVFQkSQoJCTGuRQAAACdhacRXt6+NGvVi165dGjt2rHr37q0+\nffpo3Lhx2rVrl9FtAwAAqOp0uhXRfffdp+uuu07btm3T1q1bdd111+m+++4zum0AAABVnU63Iqqo\nqNDo0aNlsVhksVg0atQoVVRUGN02AAAAr1SjAHbmmWdq8+bNrudbtmxRfHy8YY0CAACo1ulwL8hj\nl6EoLy9Xamqq6+KrGRkZOuuss0xpIAAAwDGW0+FCrFyGAgAANCqNeF9XbdTqMhQAAAANqhEvK9ZG\njW5FVFBQoFdffVU7duxQWVmZ63hycrJhDQMAAHBzOsyAHXP//fcrNjZW6enpmjJlipYsWaKzzz7b\n6Lap84ZPDK/D2zGG9SMiIrShm+AVGMe6YwzrB+PoubxlD1iNepGRkaGpU6cqMDBQI0aM0CuvvKLv\nv//e6LYBAAB4pRrNgFmtVkmSv7+/cnNz1bRpU2VmZhraMEnKfPjfhtfhzaIfvle7R17Z0M3weB2X\nva1f+yU1dDM82rGZ2JycggZuiWeLiAhlDOvo2MwX41g3DTqDeDrtAevQoYNyc3M1cuRIXXHFFQoN\nDVW3bt2MbhsAAEBVjfj2QrVRowD29NNPS5ImTJiguLg4FRQUaMCAAYY2DAAA4Pcsp9Mm/BP16NHD\niHYAAACc2ukwA3bDDTdowYIF6t27d5XE6XQ6ZbFYtGnTJsMbCAAA4HI6BLCnnnpKkrRkyRJTGgMA\nAPBHLKfDJvzIyEjZ7XY99thjmjNnjlltAgAA8Gqn3APm6+ur0tJSORwO+XjJtB8AAPBQXnIh1hpt\nwj/33HN1xx13aMSIEQoJCXEdT0hIMKxhAAAAbk6nb0F+++23kqS33nrLdcxisRDAAACAuU6HPWDH\nLFy40Oh2AAAAnJK33AuyxtcBKygoUFpamsrKylzHLrzwQkMaBQAAUK3TaQbso48+0syZM5Wfn6/I\nyEjt2bNHXbt2VWpqqtHtAwAAcCkJDKhV+Qa8a+UfqtE83pw5c7R06VLFxMTok08+0bx583TOOecY\n3TYAAACvVKMA5ufnpxYtWshut0uS+vbtq59//tnQhgEAAJhh3bp1SkpK0pAhQzR37ly38zabTVOn\nTtWQIUN0+eWXa9++fXWus0YBzGq1yul0KiYmRgsXLtTq1at19OjROlcOAADQkOx2ux599FHNmzdP\ny5cv14cffqidO3dWKbN48WKFhYXp008/1fjx4/X000/Xud4aBbBbb71VhYWF+sc//qFVq1Zp9uzZ\neuihh+pcOQAAQEPatm2bYmJi1K5dO1mtVg0fPlyrVq2qUmb16tUaM2aMJCkpKUmbNm2S0+msU701\n2oT/z3/+U4MHD9Zll12m+fPn16lCAACAxiIrK0vR0dGu51FRUdq2bZtbmVatWkmq3JYVGhqqo0eP\nKjw8/E/XW6MZsE8++UTdunXTE088oaSkJM2ZM0eZmZl/ulIAAIDGoLqZLMvvrrZfkzK1VaMA1qxZ\nM1177bVaunSpXnzxRWVkZGjQoEF1qhgAAKChRUdHV5lUysrKUmRkpFuZgwcPSpIqKipUUFCgZs2a\n1aneGl9O1uFwaM2aNXrhhRf0+eefu9ZCAQAAPFVcXJzS09O1d+9e2Ww2LV++XImJiVXKJCYmuq59\n+sknn6h37951ngGr0R6wGTNmaPny5ercubNGjx6tJ598UoGBgXWqGAAAoKH5+flp2rRpmjhxoux2\nu8aOHavOnTtr1qxZ6t69uwYNGqRx48bp7rvv1pAhQ9S0aVM999xzda+3JoWaNm2qxYsXuzagAQAA\neIuEhAQlJCRUOTZlyhTXzwEBAfrPf/5Tr3XWKIDddttt9VopAADA6azGN+MGAABoaOW+/g3dhHpB\nAAMAAB7D7qjbBVAbCwIYAADwGHW9An1jQQADAAAegwAGAABgMoeXBLAaX4gVAAAA9YMZMAAA4DG8\nZAKMAAYAADwHe8AAAABM5hABDAAAwFTMgAEAAJjMW74FSQA7gSUoUE0vvUTW2A5yFpeoYNValW7/\n0a2ctUN7hST0lX+rKDlLy5Tz/MtVzvu3a6PQiwfJr2UL2XPzlL98pcr37DOrGw3Op0mIIu68WUHn\nnSN7foGOJL+torUb3co1HTNCoYMS5BfRUvaCAuUvX6m81A8lSb4RLdRu9jNV3zcoUIdfW6i895ab\n0o+G5hMaqqj77lLwhRfInpenw6+8roJP17iVa3b5GDW7fJR8mobJWVKqglVrdeilVyW7Q77Nmipi\n6q0Kij9HlsBA2XanK+fFV1T2488N0CMAqDsHV8L3PmGXDJXTblfO0y/ILzpKza8ep4rMbFXkHKpS\nzllerpL/bVPp935q0v8vVc5ZggLV/KqxyvvwE5Xt+EWBcWep+VXjlDPrZTlLy8zsToNpecvf5Kyw\nK+O6m2Xt2EGtpt0jW1qGewi1WJT93GzZ0vbIv1WUoh+9XxWHDqto/SbZcw4r/a/jXUX9oiLU7pVZ\nKvria3M704Ai/367nOUV2n3pFQroHKvWTz6msp27ZUvLqFKuaOOXyl+xUo7CIvmEhqrV4w+o2bjR\nyn1nqSzBQSrd8YtyXpgr+9FchY1IUpsnH1Pa5dfLWVLaQD0DgD/PSybAuA7YMRZ/fwWedaYK16yT\n01au8j37VPbzTgWee7Zb2fL9B1W67QfZj+a6nbO2ayN7YVHlDIPTqdJtP8hRXKzAbmea0Y0GZwkI\nUMhfeunoonflLC1T2Y8/q+jrLQq9qL9b2byly2TblS45HCrff1DFX20+6Tg1uWiASn/YoYrsHIN7\n0DhYAgPUJKGfDs9bIGdJqUq3/aCiDZsUmjTIrWz5gYNyFBb99kJJTqf827aWJFUcyFTuO0tlP3xE\ncjiU/8EKyd9P1vZtTewNAOD3CGC/8W0RLjkcsh8+6jpWnpUtv4iIWr6TRRaLxe2oX2Rt38cz+bdp\nJafDofIDB13HbGkZ8q/BL/zAs7rKdpKl2tDEASpYva7e2tnYWdu1rRzHvftdx8p2pcl6Rky15UOH\nXKSOnyxV7Ecpssaeobz3P6r+fTt1lMXPX+X7DhjSbgAwmtPprNWjsTI9gI0cOdLsKmvEYvWXo6zq\nEqGztEw+AdZavY9t7z75hDZRYPduko+PAs/tLt/w5rL4nx6rvT6BgXIUF1c55igqlk9Q0B++rvnV\n4yQfHxV89rnbucCzusq3WVMVbfyyPpvaqFmCgo7Pav3GUVgkn+Dqx7Hg0zXanXSZ0q+coLz3l8t+\n5KhbGZ/gYEU/+E8deX2RHEXF1bwLADR+Djlr9WisDEkFK1eurPa40+lUTk7jXEJy2srlExBQ5Zgl\nIECOMlvt3qekVEffWqKwoYkKGz5UZTvTZNudLnt+QX02t9FylJa6hQSf4CA5SkpO+pqw4UlqkjhA\nB+55WKqocDvfZNAAFX3x1Wmzh06SnCUl8gkJrnLMJyRYjuKTj6Mkle87IFtahiL/focO/usx13GL\n1apWMx9R6Q8/6eiidwxpMwCYoTHPatWGIQHsrrvu0siRI6tdiisra5y/RO2Hj0g+PvINb+6aPfCP\njlTFnwiM5Rl7dfjVBZVPfCyKuPOW02bzePn+g7L4+MqvVbQqDmZKkqxnxJz0W6Chgweq2bhLdeDe\nRyr/G/yOxeqvJn17K3P6M9W82nvZ9u6TxddX/m1bu5YLAzp1dNuAXx2Lr6/827Q+/tzfX61mPCT7\nocPKfmqWYW0GADMQwP7AmWeeqb/97W/q0qWL27kvvvjCiCrrzFlertIdP6vJRf2V/8EK+UVHKuDM\nTjry2iL3whZJvr6Sj2/lcz/fyq9l2B2VT6OjVJGdI4u/n5pc1F/2/ALZdqWZ15kG5CwrU9GmrxV+\nzeXKeWGurB1jFNKrh/b/c5pb2SYJfdX8+it18P5HVZGVXe37BffpKXtRkUq3/WB00xsVZ2mZCtdu\nVIuJ1yvr388poHOsQvr10b79DL34AAAgAElEQVRb73IrGzbiYhVt2CR7bp6sHdqr+XVXqvirzZUn\nfX0V/fgDcpbZlPn4k97z9SEApy0vuQqFMQHs/vvvV5MmTao99+KLLxpRZb3IX75STUddooi7J8tZ\nUqL85StVkXNI/u3bqvm1f1X29GclSdaY9goff7XrddEP3C1b+h4dmf+mJCmkby8FdO4oSSrbmabc\nd5aa35kGdOjl1xQx5RbFLHpFjoJC5bz8msr37FPgWV0V/fC9rstLNL/uCvmGNlGbZ6e7Xlv4+Xod\neuk11/PQxAEqXL3e7C40CtnPvKio+/5PHZe9K3t+vnKeeUG2tAwFntNdbZ5+XLuGjpYkBcWdrRaT\nxssnKEj23FwVrlmvw/MW/HbuLDXp21uO0lLFrjj+Odz/jwdUuu37BukXANSFt8yAWZyNuCeZD/+7\noZvg0aIfvle7R17Z0M3weB2Xva1f+yU1dDM8WucNn0iScnJOj72QRomICGUM6ygiIlQSn8W6OjaO\nDeH7fVm1Kt+9bZRBLakb078F2ZhnwAAAAMxgegBLSUkxu0oAAOAlKhyOWj0aK0P2gJ1//vnVHnc6\nnY32W5AAAKDxa8Q7p2rFkAAWFhamlJQUtWzZ0u1cQkKCEVUCAIDTgMNLApghS5CjRo3SgQPV3+pk\nxIgRRlQJAABOA05n7R6NlWEXYj0mLy9PGRkZrqXHgQMHGlElAAA4DbAEWQOLFy9WcnKyMjMz1bVr\nV23dulXx8fFKTk42sloAAOClWIKsgeTkZKWkpKh169ZauHChUlNTFR4ebmSVAAAAjZ6hM2BWq1UB\nv93g2mazKTY2Vmlpp8cteQAAQP1jCbIGoqOjlZ+fr8GDB2vChAkKCwtTZGSkkVUCAAAv5iX5y9gA\nNnv2bEnS5MmT1atXLxUUFKh///5GVgkAALyYt+wBMzSAnahnz55mVQUAALwUS5AAAAAmYwYMAADA\nZAQwAAAAk3nLEqSh1wEDAACAOwIYAADwGE6ns1aPusjNzdWECRM0dOhQTZgwQXl5edWWu/HGG9Wj\nRw/dfPPNNX5vAhgAAPAYDmftHnUxd+5c9enTRytXrlSfPn00d+7castNnDhRTz75ZK3emwAGAAA8\nhpkzYKtWrdLo0aMlSaNHj9Znn31Wbbk+ffooJCSkVu/NJnwAAOAxzNyEf/jwYdcdfCIjI3XkyJF6\ne28CGAAA8BgO1W8AGz9+vA4dOuR2fOrUqfVaz+8RwAAAgMeo7xmw+fPnn/RcixYtlJ2drcjISGVn\nZys8PLze6mUPGAAA8BhmbsJPTEzUe++9J0l67733NGjQoHroQSUCGAAA8BgOh7NWj7qYNGmSNm7c\nqKFDh2rjxo2aNGmSJGn79u3617/+5Sp39dVXa8qUKdq0aZMGDBig9evXn/K9WYIEAAAew8xN+M2b\nN9eCBQvcjsfFxSkuLs71/M0336z1exPAAACAx/CWWxERwAAAgMeo729BNhQCGAAA8BjMgAEAAJjM\nS/IXAQwAAHgOh5ckMC5DAQAAYDJmwAAAgMdgDxgAAIDJCGAAAAAm85Y9YAQwAADgMbwlgFmc3jKX\nBwAAvN6iDVtqVf7afhcY1JK6adQzYF/u3NPQTfBovTu115T5qQ3dDI83a/wYPot11LtTe0nSkq+3\nN3BLPNvYnnHKySlo6GZ4tIiIUEliHOvo2Dg2hDreX7vRaNQBDAAA4ETesnDHdcAAAABMxgwYAADw\nGN4yA0YAAwAAHsNbvgVJAAMAAB7DS/IXAQwAAHgOliABAABMxhIkAACAyewOR0M3oV5wGQoAAACT\nMQMGAAA8BkuQAAAAJmMTPgAAgMm8JH8RwAAAgOdgCRIAAMBkLEECAACYjAAGAABgMm9ZguQ6YAAA\nACZjBgwAAHgM75j/IoABAAAP4i1LkAQwAADgMdiEDwAAYDKHgwAGAABgKmbAAAAATMYeMAAAAJN5\nR/ziOmAAAACmYwYMAAB4DG/ZA8YMGAAA8BgOp7NWj7rIzc3VhAkTNHToUE2YMEF5eXluZXbs2KEr\nrrhCw4cP18iRI/XRRx/V6L0JYAAAwGM4nc5aPepi7ty56tOnj1auXKk+ffpo7ty5bmUCAwM1c+ZM\nLV++XPPmzdP06dOVn59/yvcmgAEAAI9h5gzYqlWrNHr0aEnS6NGj9dlnn7mVOeOMM9ShQwdJUlRU\nlMLDw3XkyJFTvjd7wAAAgMcw80Kshw8fVmRkpCQpMjLylMFq27ZtKi8vV/v27U/53gQwAADgMer7\nOmDjx4/XoUOH3I5PnTq1Vu+TnZ2tu+++WzNnzpSPz6kXGAlgAADgtDV//vyTnmvRooWys7MVGRmp\n7OxshYeHV1uusLBQN998s6ZOnar4+Pga1cseMAAA4DHM3AOWmJio9957T5L03nvvadCgQW5lbDab\nbr/9do0aNUrDhg2r8XsTwAAAgMcw81uQkyZN0saNGzV06FBt3LhRkyZNkiRt375d//rXvyRJK1as\n0ObNm5WamqpRo0Zp1KhR2rFjxynfmyVIAADgMcy8EGvz5s21YMECt+NxcXGKi4uTJFfoqi0CmKSP\nU5foo5R3ZLOVqUff/rrh9jvl72+ttuwP332rhS+/qMM52erYpatu+r+71TIySpJ0360TdTg7y1W2\n3GbTOT166q6HHtPP32/XMw/dX+W9ykpLdcf903Rh3/7Gda4BDTwrVoPiusjf11dbMw7o3U3fye5w\nuJWLiWiu4eedpbYtmsnpdOrXzENa+tVW5ZeUSZISz+6snp3aq3mTIBWV2rThpzSt/uFXs7tjCjM+\ni5LksNu19I1krf/0Y5WWlCiyVWvdO+NphTRpYnwnG8CGFcu0bvn7KrfZ1P3CXho1fpL8/P3dylVU\nlOudl2Zpf9ou5R7K0cT7H1bHbt1d59ctf1/frv9cuYdzFNIkTL0GJ2nA8Nr/wwvgzzPxS5CGOu0D\n2PYt32h5ytu6Z/pTah7eQv954mGlLkrWXydMdCtbkJenF554RH+78/8U36uPli6cr5f+/bimPfuC\nJGnGy/NcZZ1Op+6+8Xpd2G+AJOnM7nGau2SZ6/yObVv1/KMP6pwLehjcw4bRtXWkBsd10YufbFBe\ncaluTOylS87rpmVbfnArG2y16ouf07TjQLYcDqfG9T5XV/e7QHM+/aKygEVatH6zDhzNV8vQEN06\ntK+OFhfrf2n7Te6Vscz6LErS0jeStXPHj3rwmf+oRUSk9meky99afdDzdL9s+05rP3xPE+97WGHN\nm2vR80/qs6Xv6OIrrq22fIcuXdU3abjeeuEZ95NOpy6/ZbKi28XoSHamXp/5mJqGt9C5ffoZ3AsA\nx3ArIi+xYdWnGjD0YrWN6aCQ0FBdeuU12vDZymrLbv5ig9q076Ce/RNktVo15prrtCdttw7s3eNW\n9ufvtyk/L1cX9q3+H+YNq1aqR9/+CggMqtf+NBY9O7XXl79mKDO3QCW2cq3c+rN6dqr+uig79mfp\nu4wDKiuvULndrvU7dumMyOPfNFn9/a/adyRPDqdT2fmF2r7noDpGtjCrK6Yx67NYVFCgle8v1YQ7\n71LLyChZLBa17XCGrF4awL7d8Ll6JCQqqm07BYU00UWjx+nb9Z9XW9bPz199Lx6hDmd2k6War5EP\nGDFabTp0lK+vryJatVG38y9Uxq8/G9wDACcycw+YkUwLYD/84D7z0Rjs35Oh9mfEup63PyNWeblH\nVVjNbQT270lXu44dXc8DAoMU2aq19u/JcCu7YdWnuvAkAaustFSbN65Xv0FD66kXjU90szDtP3L8\nnln7j+QpLChQwQGn/iUfG91SmbkFJz8f1UKZuae+zYOnMeuzuDcjTb6+vtq8YZ3uvOav+udN4/XZ\nh+8b0KPGIXvfXrVq38H1vFX7DirMy1Vxwck/YzXhdDqV/ssORbVpW8cWAjgdGbIE+fuw5XQ6ddtt\nt2nOnDlyOp06++yzjaj2TyktKVFQcIjreVBI5c8lJcVqEhZWpWxZSalCmzatciwoOFilxcVVy5WW\n6psN6zV12qPV1rn5i/VqEtZUXePOqY8uNEoBfr4qKS93PS+xVf4c6O+n4jLbSV/XunmYks7tqnmr\nvqz2/LD4rrJYLPryV/eZHk9n1mfx6KFDKi4qUub+/Xr6vwuVeWC/nrz/n4pu01bdz7ugvrvV4Gxl\npQoMDnY9Dwyq/LmstETBoaF/+n1XLX1XTodTFwxIrHMbAdTcczeMbugm1AtDAtjYsWMVHx8v/xM2\nuebm5mrGjBmyWCxKTk42otoa+WLNKs1/8XlJUpez4xQYFKSSkuO/tI79AgsKCnZ7bUBQoEp+9wuu\ntLi4yj/uUuXyUJPQ0JMGrA2ffaq+iYNlsVjq1JfG5IKObXVFn/MkSbuyDqmswq7AE/77B1orfy4t\nrzjpe7QMDdHNg/+ipV9t0+7sw27n+3ftqAtj22vWinXVbub3NA31WTy212vU1dfKGhCg9md0VK8B\nA7X1m6+9IoB9t3Gd3nu98oa5Hc7sKmtAoEpLSlzny377uS7L/5s+XaH/bVirSQ8+Vu1mfgA4FUMC\n2PPPP69FixZp4sSJSkhIkFR5MbOFCxcaUV2t/OWiQfrLRccvpPbyk9O1d/cu9epf2c49abvUtFlz\ntxkHSWrTvoM2rDq+J6estETZmQfVpn1MlXIbV508YB3OydZP27dq/OTa3eKgsduye5+27N7nen79\ngB5q07ypvkuv3CjfpnmY8ktKTzr71TwkSLcl9dXKbT9p8+69bud7dYrR4Lgu+s+KdcorLjWmEyZr\nqM9iuzMqly4t8p4/AE4U33eA4vse/8LB2y89r8w96Tqn118kSQf3pKtJ02Z/evZr89pVWrssVZMe\nqNyADwB/hiF7wC6++GK98sor2rhxo+68804dOHCg0c729E0conUrP9b+PRkqKijQB2+/qX6Dq9+b\ndcFf+mp/Rrq+2bheNptN7725SO06nKHW7Y5vLj9yKEc7tn2nvid5jy9Wf6ZO3c5WVKvWhvSnsfh6\n1x717hKjqKahCrL6a+i5XfX1zuqXDZsGB+qOpH7asCNNG39Odzt/Qce2GnHBWXpp5UYdLix2fwMv\nYdZnMapVa3U5O04fvPOmysttOrAnQ1+tX6v4nr0M7V9DOb9fgjavXa2s/XtVUlSoNe8v0fn9B560\nfEV5ucptlX8o2CsqVG6zuTbyfrdxnVYufkt/u2eawn+75AcA/BkWp8FfEdixY4emT5+unTt3atOm\nTbV67Zcn+YVd3z5OTdHylHdkK7OpR99+Gn/HFNe1l+67daJG/vUq10zFD//7VgvnvKhD2VmKPbOr\nJt51tyKiol3vtezdt7Rt89f615PPVVvXvTf/TcMuu1wJSTW/XcGf1btTe02Zn2p4PScz8KxOGhzX\n2XUdsHdOuA7YvaMG6dPtP2vL7n26+NyuGnZeN5X9bnnyn29UXrZj2tihahYSpAr78WXHzbv36t1N\n35nSj1njx3jdZ/HIoUP676xn9MuP3yusaTMNv/wKXTRshGH96v3bN2CXfL3dsDr+yIYVy7T2w/dU\nYbPp7At7a/SE49cBe/7eqRo48jLXrNmTd92q3EM5VV5/97MvqXlEpJ666zblHT0sP7/jy47xfftr\n9ISbTenH2J5xysmp25cHTncREZUzn4xj3RwbR/x5hgcwqXITflFRkZrU8iKPZv3S81YNHcC8hZkB\nzFs1dADzFgSwuiOA1Q8CWN2ZchkKi8XiCl8vvviiGVUCAAA0WqZfiDUlJcXsKgEAABoVQ74Fef75\n51d73Ol0qqyszIgqAQAAPIYhASwsLEwpKSlq2bKl27ljl6UAAAA4XRmyBDlq1CgdOHCg2nMjRhj3\nTSsAAABPYMgM2F133eX6OS8vTxkZGa6lx4EDBxpRJQAAgMcwJIAds3jxYiUnJyszM1Ndu3bV1q1b\nFR8f36C3IgIAAGhohn4LMjk5WSkpKWrdurUWLlyo1NRUhYeHG1klAABAo2doALNarQoICJAk2Ww2\nxcbGKi0tzcgqAQAAGj1DlyCjo6OVn5+vwYMHa8KECQoLC1NkZKSRVQIAADR6hgaw2bNnS5ImT56s\nXr16qaCgQP379zeySgAAgEbP0AB2op49e5pVFQAAQKNm+q2IAAAATncEMAAAAJMRwAAAAExGAAMA\nADAZAQwAAMBkBDAAAACTEcAAAABMRgADAAAwGQEMAADAZAQwAAAAkxHAAAAATEYAAwAAMBkBDAAA\nwGQEMAAAAJMRwAAAAExGAAMAADAZAQwAAMBkBDAAAACTEcAAAABMRgADAAAwGQEMAADAZAQwAAAA\nkxHAAAAATGZxOp3Ohm4EAADA6cSvoRvwR8oPZDZ0Ezyaf+toHX1rSUM3w+M1v2qsSrb/0NDN8GhB\ncWdLkoq/+baBW+LZgi88X8Vfb2noZni04J4XSJJycgoauCWeLSIitKGb4PFYggQAADAZAQwAAMBk\nBDAAAACTEcAAAABMRgADAAAwGQEMAADAZAQwAAAAkxHAAAAATEYAAwAAMBkBDAAAwGQEMAAAAJMR\nwAAAAExGAAMAADAZAQwAAMBkBDAAAACTEcAAAABMRgADAAAwGQEMAADAZAQwAAAAkxHAAAAATEYA\nAwAAMBkBDAAAwGQEMAAAAJMRwAAAAExGAAMAADAZAQwAAMBkBDAAAACTEcAAAABMRgADAAAwGQEM\nAADAZAQwAAAAkxHAAAAATEYAAwAAMBkBDAAAwGR+Dd2AhpaXn68Hn5qpTZs3q1nTppo68SYNHzzE\nrZzT6dRzc1/Rko+WS5IuG3aJ/u/mW2SxWCRJDz/9lDZv26qMffv02D/v0eiLh7lea7PZ9Nyrc/Xx\nmtUqKyvTsMRBunfynfL3887hzysu1vQPluqrXb+qWXCIbh00VEnnxLuV25K2S6+tXa2fDx5QaGCQ\n3rvrn65zRwoL9dzHH+p/6WkqKbepY2SUpiQNV/e27czsiqnyCgr08MuztWnrVjUPDdXka67VJf0H\nuJVzOp2atWihUld9JkkaPWiwpl57neuzGD/uMgUGBLieX9y3rx669XZJ0jffb9crixfrp7TdCg0J\n0YqXXzGpd+bIKyzUI6++ok3fb1ezJqG684orNewvfd3KOZ1O/eedt5T6+RpJ0uiEgZpy5dWuMbM7\nHJqzZLHeW/u5iktL1S4qSq/e/6BCQ0KqvM+k6Y/pmx9/1DcLFsnP19f4Dpokr7BQj8ybq03bt6tZ\naKju/OsVfzCObyt17W/jOGCgplx51e/GMUXvrTthHO97wDWO+7Kz9OTCZG35aYesfn4aNWCgpl51\ntXkdBRqQdyaAWnh81nPy9/PX2qWp+mnnTt123706M7aTOp1xRpVyi5ct0+qNG7Rk3muyyKKb7v67\n2rZurSsuHSVJOjO2ky6+KFHPznX/hTbvrTf1w88/6b3/zpfd4dAd99+nVxYm644JfzOlj2Z7+qMP\n5Ofrq4/+cb9+yTyov7+5QJ2jW6ljZFSVcoH+Vo08r4eGdi/X/PWfVzlXYrOpW+u2mpJ0iZqHNNGy\nbzfr728sUOrUuxUcEGBib8wzY96r8vfz0+p5/9XP6emaPOMJdenQQZ3ata9SbsmnK7Xmm6/17jPP\nSrLo1sceUdvIKF2elOQq8+7Tz6p9q1ZudQQGBGp0YqJKbf302tIlRnfJdDPm/1f+fn5aNXuOfs5I\n151PP6ku7dsr9nfBfcnqVVqzebPeeeLfslgsuuXf09UmMlKXD6r842vOksXa+usvWvDwo2rVoqV2\n7dsnq79/lff4aOMGVdgdpvXNTDMWvP7bOL5cOY7PPKUu7WMU27ZtlXJL1qzWmi2b9c4TM2SRRbfM\nnPHbOA6WJM1ZklI5jg894jaO5RUVunXmDP118BDNvH2yfHx8lJGZaXpfgYZyWi9BFpeU6NN16zT5\nbzcqOChY58edo4F/+YuWfbrSrez7Kz/WDZf/VdERkYqKiNANl1+h9z/+2HX+qjFj1PuCCxRgtbq9\n9vMvvtA1l41V07AwhTdrpmsuu0ypKz4ytG8NpcRm05off9DNFw1RcECA4mM6qP+Z3bRi6//cyp7d\ntp2GnXueWjcPdzvXJjxcV/+ln1qGhsnXx0eje/RUud2uPYcPmdEN05WUluqzr77U7VdereCgIJ3X\nrZsSelyo5WvXupX94PPPdd3ISxXVoqWiWrTQdSMv1Qefr65RPXGdO2tEwkC1jYo6dWEPU1JaqlXf\nfK3bxv1VwYGBOu/Mrko4/wJ9uGGDW9llG9bpukuGK6pFC0WGh+u6S4Zr2bp1kqT8okK98fEKPXjj\nJLVuGSGLxaJO7dpV+X+7oLhYr6Qu8crZGtc4jr286jhuXO9Wdtn6dbpu2CWKCv9tHIddomXrTxjH\nT1bowRtvqnYcP1i3VhHNmuu6YcMVFBioAKtVXdq3d6sD8Fan9QxYxr698vXxUYd2x/86PjO2kzZv\n/c6t7K70dJ0Z2+l4uU6x2pmeVrOKnE45nc4TnyorJ0cFhYUKbdLkz3egEdpz+JB8fSxq37Kl61jn\nqFb6NqOGY3USvxw8oAq7XW3DW9S1iY1SxoED8vXxUUzr1q5jXWJitOXHH93K7t63V2fGdDihXAft\n2ru3Spkbpz0gh9Opc7ucqb+Pn6A2kZGGtb2xyMg8WDmGJ8z8dWkfoy0/7XAru3vfPnVpH3NCufba\ntX+fJOnXvXvl6+urz77+Sm98/JFCgoJ0ddIwXTFkqKv8i+++rcsHDVHLps0M7FHDyMjMdB/Hdu2r\nH8f9vx/HGPdx/OYrvfHxispxHHqxaxy379qp1hERuv2pmfpx9y7Ftm2ne66/QZ3bEcJwejjtZ8Ca\nhFQNQKEhISoqLqm+bJOQE8o1UXFJSZVgdTL9evXSoiVLdCQ3V4eOHNYbvy39lJaV1bEHjU+JrUwh\nAYFVjoUEBqq4Dn0tKi3VI6mLdePARDUJDDz1CzxQcWmpmgQHVznWJDhERSXVfBZLS9Uk5HjZJiHB\nKi4tdX0WX3v0MX300hylznpBEeHhunPGE6qw243tQCNQXFpWzRgGnXwMg4NOKHd8DLOPHFFhcbEy\nMg/qw+f+o6funKo5S1P05fZtkqQfdu/Sd7/8oiuHJrm9rzcoLqvusxisotJS97Ju4xjkPo4HM/Xh\ns7P01OSpmpO6RF9u3y5JyjpyRJ98uUlXDU3SyhdeUv/4eN313DMqr6gwtoNAI2FIAEtJSXH9nJmZ\nqRtuuEE9evTQlVdeqbS0us2E1KfgoCAVFRdVOVZYXKyQE/5BqVK2qPh4uaIiBQcFuTab/pFJ116n\nbp07a9xNN+raO25XYr9+8vPzU3gz7/vrOcgaoKLfha2istI/vW+rtLxc/3grWWe3bacb+g+shxY2\nTsGBgSoqLq5yrKikWCFB1XwWAwNVeMIfCUXFJQoODHR9Fi8462z5+/srLCRE/5zwN+3Pzlbavn3G\ndqARCA4McAtbhSUlJx3DE8sWlRwfwwD/yiWySWMuU6DVqi7tY5TUu482bP1ODodDM+a/rruvu96r\nNt2fKDggsPpxrOaPnz8cR+uxcRzz2zi2d42jJAVYrYrvcqb6nRsvfz8/XX/JCOUVFmr3/v0G9g5o\nPAwJYG+88Ybr5xkzZmjYsGH6+uuvdeONN+rhhx82oso/JaZtO1XY7co44ZfTzzt3qlOHM9zKxnbo\noJ937Txeblf15aoTGBCgf02ZqtWLl+jjN99Ws7Awnd2li3y98B/w9i1ayu5wVNmrtTMzUx0jar8E\nZquo0D1vL1JEaJjuHTG6PpvZ6MS0bq0Kh0MZBw+4jv2Snq7Ydu7f+uzYtp1+SU8/ZbljLBZLjWZq\nPV1MdKvK/58zD7qO/bJnjzq2aetWtmPbtvplT8YJ5TIU+1u5zr/tQ7LI/Y+ropIS/Zi2W/e++B8N\nvv0WXTPtX5Kki++8Xd/+9FO99qehxERHVzOOGerYtppxbNNWv+zZc0K5PcfHsd3Jx7HyfLuTnAFO\nD4YvQaanp+vKK6+Uj4+PhgwZory8PKOrrLHgoCAN7j9AL77+mopLSvTt9u1a88VGjTxhr8cxlw5N\n0oLF7yorJ0fZhw5pwbvvatTFF7vOl5eXq8xWJqfTqYqKCpXZyuRwVH5D6thrnE6ntv74g+YsTNZt\n473zG5BBVqsGdjtLr675TCU2m7buydC6n3/UsHPPcyvrcDhUVl6uCkfl8lhZeblr+aHCbtd9776p\nAD8/TRtzuXx8vHu1PCgwUIN69tLLb7+tktJS/e+nHfp88zcanpDgVnZkwkAt+vADZR0+rOwjR5S8\n7ANdOjBRkrRz7x79lJYmu92u4pISPZM8X5Hh4Trjt1+eDodDZTabKirsktOpMptN5eXlpvbVKEGB\ngUq8sKdeTlmsktJSfffLz1q7ZbNG9OvnVnZEv/5atOIjZR85ouyjR7Two+UaOaDykh/toqJ03pld\n9dr778lWXq7d+/dr5Vdfqn/8+WoSHKyVL7ykt5/4t95+4t968R/3SJLefGy64jp1cqvHEwUFBiqx\nx4V6eUnK8XH8dotG9O3vVnZEv/5a9PGxcTyqhSuWa2T/343jByeM45dfqv95lf8WDO/bT9t37dSX\n32+X3eHQGx+vULPQUHVs08bU/gINxeI04E/jPn36aPjw4XI6nVq5cqVWr14t/9++ejxixAh9+OGH\nNXqf8gPGfyU5Lz9fDz45U5u2bFbTsDDdddMkDR88RFu2bdUt99yjb1ZUftPR6XTq2VfmuK4DNvaS\n4VWuAzZ+6hS3zfv/fe559Yw/T5u3btX9M6brSO5RRUdG6pbrbtCIIe7XGqtv/q2jdfQt8y81kFdc\nrCfeX6Kvd+9U06Bg3TY4SUnnxOu7jDTdtWiB1vzrYUnSlrTdun3BvCqvPS/mDL084SZ9m75bt82f\npwA/f/mcsMz73LU3KD6mZjOP9aX5VWNVsv0Hw+vJKyjQQy/N1pfbtlZee+m364B9++OPun3649q0\n6E1JlZ/F5/+/vXsNiccjEsYAAAhcSURBVHrP4zj+8SRKh9JjdL9nDwwPkXbakpUoZ3tQOSZGFkW6\n3TZINEhCKSg6G+Eup5CgCLdju420nuhimZEQCT4oMjndg05gYQ/MC0fxUqKZ/31QudaOHWdP/99/\nxt6vRzpefp/58h/nM/Of+dlvH7CUfvuA3XrwQAeOF6jh1181PDRUc6JmaUd6uqZNePvi/uqHD/WX\nfXs/WPe76G9V+Nf9tl634bO/lSS9qr5t6zqtHR3ad7xANx8+0DcjRmj7mrVa9sd43X78WJk//E03\nCv8l6d1eaj/9u28fsJTFCR/sA9bY3KzvjxfozpNfNCosXBvcSVr1bmuF/uqampS4Y7uxfcC+/sNc\nvbr1s+3r/HeOD/XNyBHavvrtfmq3f3mszB/+rhs//lPS+zkW9+0DlrIo4YN9wBqbm/X9j/94N8cw\nbXCv0CrXn/rWuVZ9S4d/KlZzW5tmTZ+uXX/e+D9bXXxuX8//TpLU1NRu6zpD3ZgxI52OEPBsKWAl\nJSUffO5yuRQeHq6mpiYVFRUpOzt7UL/HRAEbypwqYEONqQI2lJkqYEOdqQI2lFHAPg8K2O9nyzYU\nKSkpXi8fM2bMoMsXAADAUGX8hTVHjhwxvSQAAIBfMV7A+m9RAQAA8CWy5RTk3LlzvV5uWZa6huDm\nowAAAL6wpYCFhYXp7NmzGt3v39G8t8jL2+oBAAC+JLacgkxOTlZdXZ3Xr7ndbjuWBAAACBi2PAO2\nY8eOvo9bW1tVW1vbd+px8eLFdiwJAAAQMGwpYO+dOXNGHo9H9fX1mjVrlu7du6eYmBh5PB47lwUA\nAPBrtr4L0uPx6OzZs5o4caKKiopUUlKiUaNG2bkkAACA37O1gIWEhCg0NFSS1N3drZkzZ+rZs2d2\nLgkAAOD3bD0FOX78eLW1tWnJkiXauHGjwsLCNHbsWDuXBAAA8Hu2FrCjR49KkrKysrRgwQK1t7dr\n4cKFdi4JAADg92wtYP3Nnz/f1FIAAAB+zfi/IgIAAPjSUcAAAAAMo4ABAAAYRgEDAAAwjAIGAABg\nGAUMAADAMAoYAACAYRQwAAAAwyhgAAAAhlHAAAAADKOAAQAAGEYBAwAAMIwCBgAAYBgFDAAAwDAK\nGAAAgGEUMAAAAMMoYAAAAIZRwAAAAAyjgAEAABhGAQMAADCMAgYAAGAYBQwAAMCwIMuyLKdDAAAA\nfEl4BgwAAMAwChgAAIBhFDAAAADDKGAAAACGUcAAAAAMo4ABAAAYRgEDAAAwjAL2f+rs7NTWrVu1\ndOlSJSYm6uDBg05HClibN2/WihUrlJiYqL179+rNmzdORwo4ZWVlSkpKUlJSkjZv3qzm5manIwWM\n/Px8LVq0SLGxsR9cXl1drZSUFEVHR6u8vNyhdIFhoBm+V15erqioKD148MBwssAy0BzPnz+vuLg4\nJScnKzk5WWfOnHEoIT4nCtjvsGnTJpWXl6ukpES3b99WZWWl05EC0uHDh1VaWqqysjK1tLRwZ+ej\nnp4eHThwQCdPntSlS5cUFRWlU6dOOR0rYCQkJHi9Q5swYYLy8vLkdrsdSBVYBpqhJHV0dKioqEhz\n5swxnCrwfGqOy5cv18WLF3Xx4kWlpqYaTgY7BDsdIFBkZGSovr5eXV1dSk9P15o1axQXFydJCgkJ\nUXR0tBoaGhxO6f+8zXHEiBGS3haJ169fKygoyOGU/u3jGa5cuVKWZamzs1OWZamjo0PTpk1zOqZf\n8nb8xcTEeP3eyZMnS5K++orHqf35MkPp7QOsLVu26MSJEwZT+j9f54ghyMKgtLS0WJZlWZ2dnVZi\nYqLV3Nzc97XW1lbL5XJZz58/dypewBhojps2bbLmzZtnZWdnWz09PU5G9HveZnjlyhUrNjbWio+P\nt9atW8cMB/Cp23FMTIzXn8nNzbWuXLliJF8g8GWGjx49sjIzMy3Lsqz169db9+/fNxfUz/kyx3Pn\nzlnx8fGW2+22srKyrLq6OqNZYQ+eARukoqIiXb16VZL04sUL1dbWKiIiQj09PcrOzlZaWpqmTJni\ncEr/N9AcCwsL1dXVpZ07d+rmzZuKj493OKn/+niGNTU1Ki4u1oULFzRlyhTt379fBQUFysjIcDip\n/xno+MPgDXaGvb29ysvLU15enumIAcGXYzEhIUFut1shISEqLi5Wbm6uPB6PybiwAc+tD0JVVZVu\n3Lih06dPq7S0VNHR0erq6pIk7dmzR9OnT9eGDRucDRkAPjVHSQoNDZXL5dK1a9ccTOnfvM3w7t27\nkqSpU6cqKChIy5Yt0507dxxO6n9+6/jDb/Nlhi9fvtSTJ0+Unp4ul8ulu3fvatu2bbwQX74fixER\nEQoJCZEkrV69Wo8ePTIVFTaigA1Ce3u7wsPDNXz4cNXU1PTd4eXn56ujo0O7d+92OGFg8DbHV69e\nqbGxUdLb14BVVlYqMjLS4aT+y9sMx40bp5qamr53Pl6/fl0zZ850OKn/Geh2jMHzZYYjR45UVVWV\nKioqVFFRoZiYGB07dkyzZ882mNg/+Xosvv8bKUkVFRXcvoeIIMuyLKdD+Lvu7m5lZGSooaFBM2bM\nUEtLi1atWqWcnBxFRkb2PTJZv3497075BG9zXLt2rQoLC9Xd3a3e3l7FxcVp165dCg7m7Lg33maY\nmZmpp0+fyuPxKDg4WJMmTVJeXh6n1j4y0OwqKytVVlamxsZGjR07VqmpqcrKytL9+/eVmZmptrY2\nhYaGavTo0bp8+bLTV8NRvs6wv7S0NOXk5FDA5PscDx06pIqKCg0bNkzh4eHat28fJWwIoIABAAAY\nxilIAAAAwyhgAAAAhlHAAAAADKOAAQAAGEYBAwAAMIwCBgAAYBgFDAAAwDAKGAAAgGH/AVqu+hUq\n1NuTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf50d1c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fe_scatter\"></a>\n",
    "#### Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_scatter(title, x, xLabel, y, yLabel, sampleSize):\n",
    "    \n",
    "    pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "    # Grab sample\n",
    "    query = \"\"\"\n",
    "        SELECT count(*) AS n\n",
    "        FROM public.model_inputs;\n",
    "    \"\"\".format(\",\".join(contFeatureNames))\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    n = pd.DataFrame(cur.fetchall(), columns=colnames)['n'][0]\n",
    "    limit = math.floor(n * sampleSize)\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col1\n",
    "              ,{} AS col2\n",
    "        FROM public.model_inputs\n",
    "        LIMIT {};\n",
    "    \"\"\".format(x, y, limit)\n",
    "    cur.execute(query)\n",
    "\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    sample = pd.DataFrame(cur.fetchall(), columns=colnames)    \n",
    "    \n",
    "    # Generate scatterplot\n",
    "    if x == y:\n",
    "        sample\n",
    "    plt = sns.regplot(x=\"col1\", y=\"col2\", data=sample)\n",
    "    \n",
    "    # titles\n",
    "    plt.set_title(\"\\n\".join(tw.wrap(title,50)),fontsize=16)\n",
    "    plt.set_xlabel(xLabel,fontsize=16)\n",
    "    plt.set_ylabel(yLabel,fontsize=16)\n",
    "\n",
    "    # add 1000s commas\n",
    "    plt.get_yaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))\n",
    "    plt.get_xaxis().set_major_formatter(\n",
    "        matplotlib.ticker.FuncFormatter(lambda y, p: format(int(y), ',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n",
       " **Select Features:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3931c9583a40469c8f05edebac9906e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d0bac4f3d34e2081a381062902c64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAH3CAYAAACvnrZdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf50ea750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = contFeatureNames[0]\n",
    "y = contFeatureNames[1]\n",
    "\n",
    "def reset():\n",
    "    ipd.clear_output()\n",
    "    printmd(\"-----\\n **Select Features:**\")\n",
    "    ipd.display(scatterDropdown1, scatterDropdown2)\n",
    "\n",
    "    sample_scatter(\"{} by {}\".format(x, y), x, x, y, y, 1)   \n",
    "    \n",
    "def os1(res):\n",
    "    global x\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        contFeatureNames.append(x)\n",
    "        x = res['new']\n",
    "        contFeatureNames.remove(x)\n",
    "        reset()\n",
    "\n",
    "def os2(res):\n",
    "    global y\n",
    "    if res['type'] == 'change' and res['name'] == 'value':\n",
    "        y = res['new']\n",
    "        reset()\n",
    "                   \n",
    "scatterDropdown1 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=x,\n",
    "    description='x:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown2 = widgets.Dropdown(\n",
    "    options=contFeatureNames,\n",
    "    value=y,\n",
    "    description='y:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "scatterDropdown1.observe(os1)\n",
    "scatterDropdown2.observe(os2)\n",
    "\n",
    "reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train_vali_split\"></a>\n",
    "#### Training & Validation Sample Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split training and validation set\n",
    "# we are careful not to include the same customer in both sets\n",
    "# https://madlib.apache.org/docs/latest/group__grp__train__test__split.html\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model\n",
    "                        ,public.model_train\n",
    "                        ,public.model_test;\n",
    "                        \n",
    "    SELECT madlib.train_test_split(\n",
    "        'public.model_inputs',\n",
    "        'public.model',\n",
    "        0.7,\n",
    "        NULL,\n",
    "        NULL,\n",
    "        '*',\n",
    "        FALSE,\n",
    "        TRUE\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>a1_a</th>\n",
       "      <th>a4_l</th>\n",
       "      <th>a4_u</th>\n",
       "      <th>a5_g</th>\n",
       "      <th>a5_gg</th>\n",
       "      <th>a6_aa</th>\n",
       "      <th>a6_c</th>\n",
       "      <th>a6_cc</th>\n",
       "      <th>a6_d</th>\n",
       "      <th>a6_e</th>\n",
       "      <th>a6_ff</th>\n",
       "      <th>a6_i</th>\n",
       "      <th>a6_j</th>\n",
       "      <th>a6_k</th>\n",
       "      <th>a6_m</th>\n",
       "      <th>a6_q</th>\n",
       "      <th>a6_r</th>\n",
       "      <th>a6_w</th>\n",
       "      <th>a7_bb</th>\n",
       "      <th>a7_dd</th>\n",
       "      <th>a7_ff</th>\n",
       "      <th>a7_h</th>\n",
       "      <th>a7_j</th>\n",
       "      <th>a7_n</th>\n",
       "      <th>a7_o</th>\n",
       "      <th>a7_v</th>\n",
       "      <th>a9_true</th>\n",
       "      <th>a10_true</th>\n",
       "      <th>a12_true</th>\n",
       "      <th>a13_g</th>\n",
       "      <th>a13_p</th>\n",
       "      <th>approval</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a8</th>\n",
       "      <th>a11</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>3.750</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42.50</td>\n",
       "      <td>4.915</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.83</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49.50</td>\n",
       "      <td>7.585</td>\n",
       "      <td>7.585</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.00</td>\n",
       "      <td>11.750</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>551.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id  a1_a  a4_l  a4_u  a5_g  a5_gg  a6_aa  a6_c  a6_cc  a6_d  a6_e  a6_ff  \\\n",
       "0  4    0     0     1     1     0      0      0     0      0     0     0       \n",
       "1  10   0     0     0     0     0      0      0     0      0     0     0       \n",
       "2  19   0     0     1     1     0      0      0     0      1     0     0       \n",
       "3  33   0     0     1     1     0      0      0     0      0     0     0       \n",
       "4  38   1     0     1     1     0      0      0     0      0     0     0       \n",
       "\n",
       "   a6_i  a6_j  a6_k  a6_m  a6_q  a6_r  a6_w  a7_bb  a7_dd  a7_ff  a7_h  a7_j  \\\n",
       "0  0     0     0     0     0     0     1     0      0      0      0     0      \n",
       "1  0     0     0     0     0     0     1     0      0      0      0     0      \n",
       "2  0     0     0     0     0     0     0     0      0      0      1     0      \n",
       "3  1     0     0     0     0     0     0     1      0      0      0     0      \n",
       "4  0     0     0     0     0     0     0     0      0      0      1     0      \n",
       "\n",
       "   a7_n  a7_o  a7_v  a9_true  a10_true  a12_true  a13_g  a13_p  approval  \\\n",
       "0  0     0     1     1        1         1         1      0      1          \n",
       "1  0     0     1     1        0         1         1      0      1          \n",
       "2  0     0     0     1        0         1         1      0      1          \n",
       "3  0     0     0     1        1         1         1      0      1          \n",
       "4  0     0     0     1        1         1         1      0      1          \n",
       "\n",
       "      a2      a3     a8   a11    a14     a15  \n",
       "0  27.83  1.540   3.750  5.0   100.0  3.0     \n",
       "1  42.50  4.915   3.165  0.0   52.0   1442.0  \n",
       "2  21.83  0.250   0.665  0.0   0.0    0.0     \n",
       "3  49.50  7.585   7.585  15.0  0.0    5000.0  \n",
       "4  23.00  11.750  0.500  2.0   300.0  551.0   "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.model_train\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest (MADlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_train_model\"></a>\n",
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# traing random forest model\n",
    "# https://madlib.apache.org/docs/latest/group__grp__random__forest.html\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS public.rf_model_output, public.rf_model_output_summary, public.rf_model_output_group;\n",
    "SELECT madlib.forest_train(\n",
    "            'public.model_train',\n",
    "            'public.rf_model_output',\n",
    "            '_id',\n",
    "            'approval',\n",
    "            '{}',\n",
    "            null,\n",
    "            null,\n",
    "            10::integer,\n",
    "            5::integer,\n",
    "            true::boolean,\n",
    "            5::integer,\n",
    "            10::integer,\n",
    "            3::integer,\n",
    "            1::integer,\n",
    "            10::integer\n",
    "        )\n",
    "\"\"\".format(','.join(featureNames))\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>is_classification</th>\n",
       "      <th>source_table</th>\n",
       "      <th>model_table</th>\n",
       "      <th>id_col_name</th>\n",
       "      <th>dependent_varname</th>\n",
       "      <th>independent_varnames</th>\n",
       "      <th>cat_features</th>\n",
       "      <th>con_features</th>\n",
       "      <th>grouping_cols</th>\n",
       "      <th>num_trees</th>\n",
       "      <th>num_random_features</th>\n",
       "      <th>max_tree_depth</th>\n",
       "      <th>min_split</th>\n",
       "      <th>min_bucket</th>\n",
       "      <th>num_splits</th>\n",
       "      <th>verbose</th>\n",
       "      <th>importance</th>\n",
       "      <th>num_permutations</th>\n",
       "      <th>num_all_groups</th>\n",
       "      <th>num_failed_groups</th>\n",
       "      <th>total_rows_processed</th>\n",
       "      <th>total_rows_skipped</th>\n",
       "      <th>dependent_var_levels</th>\n",
       "      <th>dependent_var_type</th>\n",
       "      <th>independent_var_types</th>\n",
       "      <th>null_proxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest_train</td>\n",
       "      <td>True</td>\n",
       "      <td>public.model_train</td>\n",
       "      <td>public.rf_model_output</td>\n",
       "      <td>_id</td>\n",
       "      <td>approval</td>\n",
       "      <td>a1_a,a4_u,a5_g,a6_aa,a6_c,a6_cc,a6_d,a6_e,a6_ff,a6_i,a6_j,a6_k,a6_m,a6_q,a6_r,a6_w,a7_bb,a7_dd,a7_ff,a7_h,a7_j,a7_n,a7_v,a9_true,a10_true,a12_true,a13_g,a13_p,a2,a3,a8,a11,a14,a15</td>\n",
       "      <td>a1_a,a4_u,a5_g,a6_aa,a6_c,a6_cc,a6_d,a6_e,a6_ff,a6_i,a6_j,a6_k,a6_m,a6_q,a6_r,a6_w,a7_bb,a7_dd,a7_ff,a7_h,a7_j,a7_n,a7_v,a9_true,a10_true,a12_true,a13_g,a13_p</td>\n",
       "      <td>a2,a3,a8,a11,a14,a15</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>\"0\",\"1\"</td>\n",
       "      <td>integer</td>\n",
       "      <td>integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, double precision, double precision, double precision, double precision, double precision, double precision</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         method  is_classification        source_table  \\\n",
       "0  forest_train  True               public.model_train   \n",
       "\n",
       "              model_table id_col_name dependent_varname  \\\n",
       "0  public.rf_model_output  _id         approval           \n",
       "\n",
       "                                                                                                                                                                  independent_varnames  \\\n",
       "0  a1_a,a4_u,a5_g,a6_aa,a6_c,a6_cc,a6_d,a6_e,a6_ff,a6_i,a6_j,a6_k,a6_m,a6_q,a6_r,a6_w,a7_bb,a7_dd,a7_ff,a7_h,a7_j,a7_n,a7_v,a9_true,a10_true,a12_true,a13_g,a13_p,a2,a3,a8,a11,a14,a15   \n",
       "\n",
       "                                                                                                                                                     cat_features  \\\n",
       "0  a1_a,a4_u,a5_g,a6_aa,a6_c,a6_cc,a6_d,a6_e,a6_ff,a6_i,a6_j,a6_k,a6_m,a6_q,a6_r,a6_w,a7_bb,a7_dd,a7_ff,a7_h,a7_j,a7_n,a7_v,a9_true,a10_true,a12_true,a13_g,a13_p   \n",
       "\n",
       "           con_features grouping_cols  num_trees  num_random_features  \\\n",
       "0  a2,a3,a8,a11,a14,a15  None          10         5                     \n",
       "\n",
       "   max_tree_depth  min_split  min_bucket  num_splits  verbose  importance  \\\n",
       "0  10              3          1           10          False    True         \n",
       "\n",
       "   num_permutations  num_all_groups  num_failed_groups  total_rows_processed  \\\n",
       "0  5                 1               0                  483                    \n",
       "\n",
       "   total_rows_skipped dependent_var_levels dependent_var_type  \\\n",
       "0  0                   \"0\",\"1\"              integer             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                    independent_var_types  \\\n",
       "0  integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, integer, double precision, double precision, double precision, double precision, double precision, double precision   \n",
       "\n",
       "  null_proxy  \n",
       "0  None       "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view model summary\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.rf_model_output_summary\n",
    "\"\"\"\n",
    "\n",
    "df = query_gpdb(query)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_variable_importance\"></a>\n",
    "#### Variable Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "query = \"\"\"\n",
    "    SELECT 'cat' AS type\n",
    "          ,unnest(string_to_array(cat_features,',')) AS feature_name\n",
    "          ,unnest(cat_var_importance) AS feature_importance\n",
    "    FROM public.rf_model_output_group l\n",
    "        ,public.rf_model_output_summary r\n",
    "    UNION\n",
    "    SELECT 'con' AS type\n",
    "          ,unnest(string_to_array(con_features,',')) AS feature_name\n",
    "          ,unnest(con_var_importance) AS feature_importance\n",
    "    FROM public.rf_model_output_group l\n",
    "        ,public.rf_model_output_summary r\n",
    "    ORDER BY 3 DESC\n",
    "\"\"\"\n",
    "\n",
    "df = query_gpdb(query)\n",
    "ipd.display(df.head(10))\n",
    "bar_plot(df,\"Feature Importance\",\"feature_name\",'Feature Name',\"feature_importance\",\"Feature Importance\", \"#4378E2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Note - Variable importance is computed in MADlib RF as the difference in prediction\n",
    "accuracy between original data and permuted data from out-of-bag\n",
    "samples (OOB). Permuted data is defined as each variable resampled from\n",
    "its own distribution. This value can end up being negative if the number\n",
    "of levels for a variable is small and is unbalanced, as the\n",
    "redistribution doesn't change the data much.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_score_out_of_sample\"></a>\n",
    "#### Score Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score out-of-sample\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored;\n",
    "    SELECT madlib.forest_predict('public.rf_model_output',\n",
    "                                 'public.model_test',\n",
    "                                 'public.model_test_scored',\n",
    "                                 'prob');\n",
    "                \n",
    "    DROP TABLE IF EXISTS public.model_test_scored_tmp;\n",
    "    CREATE TABLE public.model_test_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM public.model_test_scored\n",
    "    JOIN public.model_test\n",
    "    USING (_id);\n",
    "    DROP TABLE public.model_test_scored;\n",
    "    ALTER TABLE public.model_test_scored_tmp RENAME TO model_test_scored;\n",
    "    SELECT * FROM public.model_test_scored LIMIT 0;\n",
    "    \n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_auc\"></a>\n",
    "#### Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n",
       " **AUC =** 0.93461"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# auc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_auc;\n",
    "    SELECT madlib.area_under_roc(\n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_auc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM public.model_test_scored_auc;\n",
    "\"\"\"\n",
    "auc = query_gpdb(query)['area_under_roc'][0]\n",
    "\n",
    "message = \"\"\"-----\\n **AUC =** {:0.5f}\"\"\".format(auc)\n",
    "printmd(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_roc\"></a>\n",
    "#### Receiver Operating Characteristic Graph (ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHwCAYAAACluRYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPBERkZ76f2MrLEIu59tgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf3b64bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_roc;\n",
    "    SELECT madlib.binary_classifier( \n",
    "        'public.model_test_scored'\n",
    "       ,'public.model_test_scored_roc'\n",
    "       ,'estimated_prob_1'\n",
    "       ,'approval'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT threshold\n",
    "          ,fpr\n",
    "          ,tpr\n",
    "    FROM public.model_test_scored_roc\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "# roc curve\n",
    "pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(df['fpr'], df['tpr'], color='darkgreen', lw=lw, label='AUC {:0.2f}'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf_confusion_matrix\"></a>\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "      <th>pred</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs  pred  num\n",
       "0  0    0     110\n",
       "1  0    1     11 \n",
       "2  1    0     13 \n",
       "3  1    1     73 "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix (inclusive)\n",
    "cutoff = 0.5\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT approval AS obs\n",
    "              ,CASE WHEN estimated_prob_1 >= {} THEN 1 ELSE 0 END AS pred\n",
    "              ,count(*) AS num\n",
    "        FROM public.model_test_scored\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(cutoff)\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost (PL/Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_load_plpython_udf\"></a>\n",
    "#### Load PL/Python UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "schema \"xgbdemo\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-b024992d57fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../sql/xgboost_gridsearch.sql\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m: schema \"xgbdemo\" already exists\n"
     ]
    }
   ],
   "source": [
    "cur.execute(open(\"../sql/xgboost_gridsearch.sql\", \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_train_model\"></a>\n",
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS public.rf_model_output, public.rf_model_output_summary, public.rf_model_output_group;\n",
    "SELECT\n",
    "    xgbdemo.xgboost_grid_search(\n",
    "        'public',--training table_schema\n",
    "        'model_train',--training table_name\n",
    "        '_id', -- id column\n",
    "        'approval', -- class label column\n",
    "        -- Columns to exclude from features (independent variables)\n",
    "        ARRAY[\n",
    "            '_id', \n",
    "            'approval'\n",
    "        ],\n",
    "        --XGBoost grid search parameters\n",
    "        $$\n",
    "            {\n",
    "                'learning_rate': [0.1, 0.3, 0.4], #Regularization on weights (eta). For smaller values, increase n_estimators\n",
    "                'max_depth': [12, 14],#Larger values could lead to overfitting\n",
    "                'subsample': [0.9, 1.0],#introduce randomness in samples picked to prevent overfitting\n",
    "                'colsample_bytree': [0.9, 1.0],#introduce randomness in features picked to prevent overfitting\n",
    "                'min_child_weight':[1, 4],#larger values will prevent over-fitting\n",
    "                'n_estimators':[200, 400, 600] #More estimators, lesser variance (better fit on test set)\n",
    "            }\n",
    "        $$,\n",
    "        --Grid search parameters temp table (will be dropped when session ends)\n",
    "        'xgb_params_temp_tbl',\n",
    "        --Grid search results table.\n",
    "        'public.xgb_mdl_results',\n",
    "        --class weights (set it to empty string '' if you want it to be automatic)\n",
    "        ''\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdl_train_ts</th>\n",
       "      <th>mdl_name</th>\n",
       "      <th>metrics</th>\n",
       "      <th>features</th>\n",
       "      <th>mdl</th>\n",
       "      <th>params</th>\n",
       "      <th>params_indx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.916667  0.830189  0.871287     53.0\\n1      1   0.816327  0.909091  0.860215     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.851852  0.867925  0.859813     53.0\\n1      1   0.837209  0.818182  0.827586     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.905660  0.905660  0.905660     53.0\\n1      1   0.886364  0.886364  0.886364     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.937500  0.849057  0.891089     53.0\\n1      1   0.836735  0.931818  0.881720     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.916667  0.830189  0.871287     53.0\\n1      1   0.816327  0.909091  0.860215     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.851852  0.867925  0.859813     53.0\\n1      1   0.837209  0.818182  0.827586     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.905660  0.905660  0.905660     53.0\\n1      1   0.886364  0.886364  0.886364     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.937500  0.849057  0.891089     53.0\\n1      1   0.836735  0.931818  0.881720     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2018-02-06 17:42:38.030966+00:00</td>\n",
       "      <td>public.model_train_xgboost</td>\n",
       "      <td>class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0</td>\n",
       "      <td>[a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]</td>\n",
       "      <td>[c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]</td>\n",
       "      <td>('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mdl_train_ts                    mdl_name  \\\n",
       "0   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "1   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "2   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "3   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "4   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "5   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "6   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "7   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "8   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "9   2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "10  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "11  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "12  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "13  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "14  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "15  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "16  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "17  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "18  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "19  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "20  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "21  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "22  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "23  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "24  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "25  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "26  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "27  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "28  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "29  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "30  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "31  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "32  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "33  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "34  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "35  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "36  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "37  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "38  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "39  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "40  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "41  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "42  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "43  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "44  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "45  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "46  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "47  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "48  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "49  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "50  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "51  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "52  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "53  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "54  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "55  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "56  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "57  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "58  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "59  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "60  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "61  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "62  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "63  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "64  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "65  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "66  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "67  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "68  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "69  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "70  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "71  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "72  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "73  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "74  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "75  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "76  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "77  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "78  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "79  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "80  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "81  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "82  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "83  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "84  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "85  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "86  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "87  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "88  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "89  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "90  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "91  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "92  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "93  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "94  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "95  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "96  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "97  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "98  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "99  2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "100 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "101 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "102 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "103 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "104 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "105 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "106 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "107 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "108 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "109 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "110 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "111 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "112 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "113 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "114 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "115 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "116 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "117 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "118 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "119 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "120 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "121 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "122 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "123 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "124 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "125 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "126 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "127 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "128 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "129 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "130 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "131 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "132 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "133 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "134 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "135 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "136 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "137 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "138 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "139 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "140 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "141 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "142 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "143 2018-02-06 17:42:38.030966+00:00  public.model_train_xgboost   \n",
       "\n",
       "                                                                                                                                                  metrics  \\\n",
       "0       class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0   \n",
       "1       class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "2       class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "3       class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "4       class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "5       class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "6       class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0   \n",
       "7       class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "8       class  precision    recall    fscore  support\\n0      0   0.916667  0.830189  0.871287     53.0\\n1      1   0.816327  0.909091  0.860215     44.0   \n",
       "9       class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "10      class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "11      class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "12      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "13      class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "14      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "15      class  precision    recall    fscore  support\\n0      0   0.851852  0.867925  0.859813     53.0\\n1      1   0.837209  0.818182  0.827586     44.0   \n",
       "16      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "17      class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "18      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "19      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "20      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "21      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "22      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "23      class  precision    recall    fscore  support\\n0      0   0.905660  0.905660  0.905660     53.0\\n1      1   0.886364  0.886364  0.886364     44.0   \n",
       "24      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "25      class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0   \n",
       "26      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "27      class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0   \n",
       "28      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "29      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "30      class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "31      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "32      class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "33      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "34      class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "35      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "36      class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "37      class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0   \n",
       "38      class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "39      class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0   \n",
       "40      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "41      class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "42      class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0   \n",
       "43      class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "44      class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "45      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "46      class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "47      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "48      class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "49      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "50      class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "51      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "52      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "53      class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "54      class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "55      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "56      class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "57      class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "58      class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "59      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "60      class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0   \n",
       "61      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "62      class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "63      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "64      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "65      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "66      class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "67      class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "68      class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "69      class  precision    recall    fscore  support\\n0      0   0.937500  0.849057  0.891089     53.0\\n1      1   0.836735  0.931818  0.881720     44.0   \n",
       "70      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "71      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "72      class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0   \n",
       "73      class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "74      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "75      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "76      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "77      class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "78      class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0   \n",
       "79      class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "80      class  precision    recall    fscore  support\\n0      0   0.916667  0.830189  0.871287     53.0\\n1      1   0.816327  0.909091  0.860215     44.0   \n",
       "81      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "82      class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "83      class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "84      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "85      class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "86      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "87      class  precision    recall    fscore  support\\n0      0   0.851852  0.867925  0.859813     53.0\\n1      1   0.837209  0.818182  0.827586     44.0   \n",
       "88      class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "89      class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "90      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "91      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "92      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "93      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "94      class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "95      class  precision    recall    fscore  support\\n0      0   0.905660  0.905660  0.905660     53.0\\n1      1   0.886364  0.886364  0.886364     44.0   \n",
       "96      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "97      class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0   \n",
       "98      class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "99      class  precision    recall    fscore  support\\n0      0   0.888889  0.905660  0.897196     53.0\\n1      1   0.883721  0.863636  0.873563     44.0   \n",
       "100     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "101     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "102     class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "103     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "104     class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "105     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "106     class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "107     class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "108     class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "109     class  precision    recall    fscore  support\\n0      0   0.865385  0.849057  0.857143     53.0\\n1      1   0.822222  0.840909  0.831461     44.0   \n",
       "110     class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "111     class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0   \n",
       "112     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "113     class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "114     class  precision    recall    fscore  support\\n0      0   0.897959  0.830189  0.862745     53.0\\n1      1   0.812500  0.886364  0.847826     44.0   \n",
       "115     class  precision    recall    fscore  support\\n0      0   0.880000  0.830189  0.854369     53.0\\n1      1   0.808511  0.863636  0.835165     44.0   \n",
       "116     class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "117     class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "118     class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "119     class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "120     class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "121     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "122     class  precision    recall    fscore  support\\n0      0   0.870370  0.886792  0.878505     53.0\\n1      1   0.860465  0.840909  0.850575     44.0   \n",
       "123     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "124     class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "125     class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "126     class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "127     class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "128     class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "129     class  precision    recall    fscore  support\\n0      0   0.921569  0.886792  0.903846     53.0\\n1      1   0.869565  0.909091  0.888889     44.0   \n",
       "130     class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "131     class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "132     class  precision    recall    fscore  support\\n0      0   0.849057  0.849057  0.849057     53.0\\n1      1   0.818182  0.818182  0.818182     44.0   \n",
       "133     class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "134     class  precision    recall    fscore  support\\n0      0   0.867925  0.867925  0.867925     53.0\\n1      1   0.840909  0.840909  0.840909     44.0   \n",
       "135     class  precision    recall    fscore  support\\n0      0   0.886792  0.886792  0.886792     53.0\\n1      1   0.863636  0.863636  0.863636     44.0   \n",
       "136     class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "137     class  precision    recall    fscore  support\\n0      0   0.884615  0.867925  0.876190     53.0\\n1      1   0.844444  0.863636  0.853933     44.0   \n",
       "138     class  precision    recall    fscore  support\\n0      0   0.900000  0.849057  0.873786     53.0\\n1      1   0.829787  0.886364  0.857143     44.0   \n",
       "139     class  precision    recall    fscore  support\\n0      0   0.918367  0.849057  0.882353     53.0\\n1      1   0.833333  0.909091  0.869565     44.0   \n",
       "140     class  precision    recall    fscore  support\\n0      0   0.901961  0.867925  0.884615     53.0\\n1      1   0.847826  0.886364  0.866667     44.0   \n",
       "141     class  precision    recall    fscore  support\\n0      0   0.937500  0.849057  0.891089     53.0\\n1      1   0.836735  0.931818  0.881720     44.0   \n",
       "142     class  precision    recall    fscore  support\\n0      0   0.903846  0.886792  0.895238     53.0\\n1      1   0.866667  0.886364  0.876404     44.0   \n",
       "143     class  precision    recall    fscore  support\\n0      0   0.882353  0.849057  0.865385     53.0\\n1      1   0.826087  0.863636  0.844444     44.0   \n",
       "\n",
       "                                                                                                                                                                                                                                      features  \\\n",
       "0    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "1    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "2    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "3    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "4    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "5    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "6    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "7    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "8    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "9    [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "10   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "11   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "12   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "13   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "14   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "15   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "16   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "17   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "18   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "19   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "20   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "21   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "22   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "23   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "24   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "25   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "26   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "27   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "28   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "29   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "30   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "31   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "32   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "33   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "34   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "35   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "36   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "37   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "38   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "39   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "40   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "41   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "42   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "43   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "44   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "45   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "46   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "47   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "48   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "49   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "50   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "51   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "52   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "53   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "54   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "55   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "56   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "57   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "58   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "59   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "60   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "61   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "62   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "63   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "64   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "65   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "66   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "67   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "68   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "69   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "70   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "71   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "72   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "73   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "74   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "75   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "76   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "77   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "78   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "79   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "80   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "81   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "82   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "83   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "84   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "85   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "86   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "87   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "88   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "89   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "90   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "91   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "92   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "93   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "94   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "95   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "96   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "97   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "98   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "99   [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "100  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "101  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "102  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "103  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "104  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "105  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "106  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "107  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "108  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "109  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "110  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "111  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "112  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "113  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "114  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "115  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "116  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "117  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "118  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "119  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "120  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "121  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "122  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "123  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "124  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "125  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "126  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "127  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "128  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "129  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "130  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "131  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "132  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "133  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "134  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "135  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "136  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "137  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "138  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "139  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "140  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "141  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "142  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "143  [a10_true, a11, a12_true, a13_g, a13_p, a14, a15, a1_a, a2, a3, a4_l, a4_u, a5_g, a5_gg, a6_aa, a6_c, a6_cc, a6_d, a6_e, a6_ff, a6_i, a6_j, a6_k, a6_m, a6_q, a6_r, a6_w, a7_bb, a7_dd, a7_ff, a7_h, a7_j, a7_n, a7_o, a7_v, a8, a9_true]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              mdl  \\\n",
       "0    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "1    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "2    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "3    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "4    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "5    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "6    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "7    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "8    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "9    [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "10   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "11   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "12   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "13   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "14   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "15   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "16   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "17   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "18   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "19   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "20   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "21   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "22   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "23   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "24   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "25   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "26   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "27   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "28   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "29   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "30   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "31   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "32   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "33   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "34   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "35   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "36   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "37   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "38   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "39   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "40   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "41   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "42   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "43   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "44   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "45   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "46   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "47   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "48   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "49   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "50   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "51   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "52   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "53   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "54   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "55   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "56   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "57   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "58   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "59   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "60   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "61   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "62   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "63   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "64   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "65   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "66   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "67   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "68   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "69   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "70   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "71   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "72   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "73   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "74   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "75   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "76   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "77   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "78   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "79   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "80   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "81   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "82   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "83   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "84   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "85   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "86   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "87   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "88   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "89   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "90   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "91   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "92   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "93   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "94   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "95   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "96   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "97   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "98   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "99   [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "100  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "101  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "102  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "103  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "104  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "105  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "106  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "107  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "108  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "109  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "110  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "111  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "112  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "113  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "114  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "115  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "116  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "117  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "118  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "119  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "120  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "121  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "122  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "123  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "124  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "125  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "126  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "127  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "128  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "129  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "130  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "131  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "132  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "133  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "134  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "135  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "136  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "137  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "138  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "139  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "140  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "141  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "142  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "143  [c, c, o, p, y, _, r, e, g, \\n, _, r, e, c, o, n, s, t, r, u, c, t, o, r, \\n, p, 1, \\n, (, c, x, g, b, o, o, s, t, ., s, k, l, e, a, r, n, \\n, X, G, B, C, l, a, s, s, i, f, i, e, r, \\n, p, 2, \\n, c, _, _, b, u, i, l, t, i, n, _, _, \\n, o, b, j, e, c, t, \\n, p, 3, \\n, N, t, R, p, 4, \\n, (, d, p, 5, \\n, S, ', r, ...]   \n",
       "\n",
       "                                                                                                                       params  \\\n",
       "0    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "1    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "2    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "3    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "4    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "5    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "6    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "7    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "8    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "9    ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "10   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "11   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "12   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "13   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "14   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "15   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "16   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "17   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "18   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "19   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "20   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "21   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "22   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "23   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "24   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "25   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "26   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "27   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "28   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "29   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "30   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "31   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "32   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "33   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "34   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "35   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "36   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "37   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "38   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "39   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "40   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "41   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "42   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "43   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "44   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "45   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "46   ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "47   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "48   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "49   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "50   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "51   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "52   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "53   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "54   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "55   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "56   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "57   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "58   ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "59   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "60   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "61   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "62   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "63   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "64   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "65   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "66   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=12')   \n",
       "67   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=12')   \n",
       "68   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=12')   \n",
       "69   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=12')   \n",
       "70   ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=12')   \n",
       "71   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=12')   \n",
       "72   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "73   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "74   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "75   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "76   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "77   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "78   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "79   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "80   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "81   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "82   ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "83   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "84   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "85   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "86   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "87   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "88   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "89   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "90   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "91   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "92   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "93   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "94   ('colsample_bytree=0.9', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "95   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "96   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "97   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "98   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "99   ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "100  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "101  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "102  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "103  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "104  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "105  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "106  ('colsample_bytree=0.9', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "107  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "108  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "109  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "110  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "111  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "112  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "113  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "114  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "115  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "116  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "117  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "118  ('colsample_bytree=1.0', 'learning_rate=0.1', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "119  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "120  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "121  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "122  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "123  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "124  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "125  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "126  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "127  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "128  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "129  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "130  ('colsample_bytree=1.0', 'learning_rate=0.3', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "131  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "132  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "133  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "134  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "135  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "136  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=1', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "137  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "138  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=200', 'subsample=1.0', 'max_depth=14')   \n",
       "139  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=0.9', 'max_depth=14')   \n",
       "140  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=400', 'subsample=1.0', 'max_depth=14')   \n",
       "141  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=0.9', 'max_depth=14')   \n",
       "142  ('colsample_bytree=1.0', 'learning_rate=0.4', 'min_child_weight=4', 'n_estimators=600', 'subsample=1.0', 'max_depth=14')   \n",
       "143  ('colsample_bytree=0.9', 'learning_rate=0.1', 'min_child_weight=1', 'n_estimators=200', 'subsample=0.9', 'max_depth=14')   \n",
       "\n",
       "     params_indx  \n",
       "0    3            \n",
       "1    5            \n",
       "2    7            \n",
       "3    9            \n",
       "4    11           \n",
       "5    13           \n",
       "6    15           \n",
       "7    17           \n",
       "8    19           \n",
       "9    21           \n",
       "10   23           \n",
       "11   25           \n",
       "12   27           \n",
       "13   29           \n",
       "14   31           \n",
       "15   33           \n",
       "16   35           \n",
       "17   37           \n",
       "18   39           \n",
       "19   41           \n",
       "20   43           \n",
       "21   45           \n",
       "22   47           \n",
       "23   49           \n",
       "24   51           \n",
       "25   53           \n",
       "26   55           \n",
       "27   57           \n",
       "28   59           \n",
       "29   61           \n",
       "30   63           \n",
       "31   65           \n",
       "32   67           \n",
       "33   69           \n",
       "34   71           \n",
       "35   73           \n",
       "36   75           \n",
       "37   77           \n",
       "38   79           \n",
       "39   81           \n",
       "40   83           \n",
       "41   85           \n",
       "42   87           \n",
       "43   89           \n",
       "44   91           \n",
       "45   93           \n",
       "46   95           \n",
       "47   97           \n",
       "48   99           \n",
       "49   101          \n",
       "50   103          \n",
       "51   105          \n",
       "52   107          \n",
       "53   109          \n",
       "54   111          \n",
       "55   113          \n",
       "56   115          \n",
       "57   117          \n",
       "58   119          \n",
       "59   121          \n",
       "60   123          \n",
       "61   125          \n",
       "62   127          \n",
       "63   129          \n",
       "64   131          \n",
       "65   133          \n",
       "66   135          \n",
       "67   137          \n",
       "68   139          \n",
       "69   141          \n",
       "70   143          \n",
       "71   1            \n",
       "72   4            \n",
       "73   6            \n",
       "74   8            \n",
       "75   10           \n",
       "76   12           \n",
       "77   14           \n",
       "78   16           \n",
       "79   18           \n",
       "80   20           \n",
       "81   22           \n",
       "82   24           \n",
       "83   26           \n",
       "84   28           \n",
       "85   30           \n",
       "86   32           \n",
       "87   34           \n",
       "88   36           \n",
       "89   38           \n",
       "90   40           \n",
       "91   42           \n",
       "92   44           \n",
       "93   46           \n",
       "94   48           \n",
       "95   50           \n",
       "96   52           \n",
       "97   54           \n",
       "98   56           \n",
       "99   58           \n",
       "100  60           \n",
       "101  62           \n",
       "102  64           \n",
       "103  66           \n",
       "104  68           \n",
       "105  70           \n",
       "106  72           \n",
       "107  74           \n",
       "108  76           \n",
       "109  78           \n",
       "110  80           \n",
       "111  82           \n",
       "112  84           \n",
       "113  86           \n",
       "114  88           \n",
       "115  90           \n",
       "116  92           \n",
       "117  94           \n",
       "118  96           \n",
       "119  98           \n",
       "120  100          \n",
       "121  102          \n",
       "122  104          \n",
       "123  106          \n",
       "124  108          \n",
       "125  110          \n",
       "126  112          \n",
       "127  114          \n",
       "128  116          \n",
       "129  118          \n",
       "130  120          \n",
       "131  122          \n",
       "132  124          \n",
       "133  126          \n",
       "134  128          \n",
       "135  130          \n",
       "136  132          \n",
       "137  134          \n",
       "138  136          \n",
       "139  138          \n",
       "140  140          \n",
       "141  142          \n",
       "142  144          \n",
       "143  2            "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view resuls\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM public.xgb_mdl_results\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_score_out_of_sample\"></a>\n",
    "#### Score Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score out-of-sample\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_xg;\n",
    "    SELECT\n",
    "    xgbdemo.xgboost_mdl_score(\n",
    "        'public.model_test', -- scoring table\n",
    "        '_id', -- id column\n",
    "        null, -- class label column, NULL if unavailable\n",
    "        'public.xgb_mdl_results', -- model table\n",
    "        'params_indx = 5', -- model filter, set to 'True' if no filter\n",
    "        'public.model_test_scored_xg'\n",
    "    );   \n",
    "    \n",
    "                \n",
    "    DROP TABLE IF EXISTS public.model_test_scored_tmp;\n",
    "    CREATE TABLE public.model_test_scored_tmp AS\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT _id AS _id\n",
    "              ,class_label_predicted\n",
    "        FROM public.model_test_scored_xg\n",
    "    ) l JOIN public.model_test\n",
    "    USING (_id);\n",
    "    DROP TABLE public.model_test_scored_xg;\n",
    "    ALTER TABLE public.model_test_scored_tmp RENAME TO model_test_scored_xg;\n",
    "\"\"\"\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_auc\"></a>\n",
    "#### Area Under ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "-----\n",
       " **AUC =** 0.91304"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# auc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_xg_auc;\n",
    "    SELECT madlib.area_under_roc(\n",
    "        'public.model_test_scored_xg'\n",
    "       ,'public.model_test_scored_xg_auc'\n",
    "       ,'class_label_predicted'\n",
    "       ,'approval'\n",
    "    )\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM public.model_test_scored_xg_auc;\n",
    "\"\"\"\n",
    "auc = query_gpdb(query)['area_under_roc'][0]\n",
    "\n",
    "message = \"\"\"-----\\n **AUC =** {:0.5f}\"\"\".format(auc)\n",
    "printmd(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_roc\"></a>\n",
    "#### Receiver Operating Characteristic Graph (ROC Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAHwCAYAAACluRYsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fccf4da9550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc\n",
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.model_test_scored_xg_roc;\n",
    "    SELECT madlib.binary_classifier( \n",
    "        'public.model_test_scored_xg'\n",
    "       ,'public.model_test_scored_xg_roc'\n",
    "       ,'class_label_predicted'\n",
    "       ,'approval'\n",
    "    );\n",
    "\"\"\"\n",
    "cur.execute(query)\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT threshold\n",
    "          ,fpr\n",
    "          ,tpr\n",
    "    FROM public.model_test_scored_roc\n",
    "    ORDER BY 1\n",
    "\"\"\"\n",
    "df = query_gpdb(query)\n",
    "\n",
    "# roc curve\n",
    "pylab.rcParams['figure.figsize'] = (8, 8)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(df['fpr'], df['tpr'], color='darkgreen', lw=lw, label='AUC {:0.2f}'.format(auc))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"xg_confusion_matrix\"></a>\n",
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "      <th>pred</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs  pred  num\n",
       "0  0    0     90 \n",
       "1  0    1     16 \n",
       "2  1    0     13 \n",
       "3  1    1     88 "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix (inclusive)\n",
    "cutoff = 0.5\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT approval AS obs\n",
    "              ,CASE WHEN class_label_predicted >= {} THEN 1 ELSE 0 END AS pred\n",
    "              ,count(*) AS num\n",
    "        FROM public.model_test_scored_xg\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY 1,2\n",
    "    \"\"\".format(cutoff)\n",
    "\n",
    "query_gpdb(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Model Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_scoring_Example\"></a>\n",
    "#### Model Scoring Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Loan Approval Results \n",
       "------\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InternalError",
     "evalue": "plpy.Error: Random forest error: Input table 'public.rf_model_output' does not exist (plpython.c:4960)\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"forest_predict\", line 23, in <module>\n    return random_forest.forest_predict(**globals())\n  PL/Python function \"forest_predict\", line 687, in forest_predict\n  PL/Python function \"forest_predict\", line 1394, in _validate_predict\n  PL/Python function \"forest_predict\", line 602, in input_tbl_valid\nPL/Python function \"forest_predict\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-28e753cedc6c>\u001b[0m in \u001b[0;36mon_appbutton_click\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mmodelInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyWidgets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"**Approval Score:** {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-28e753cedc6c>\u001b[0m in \u001b[0;36mrf_score\u001b[0;34m(modelInputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \"\"\".format(ddlString, \",\".join(str(x) for x in modelInputs))\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_gpdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimated_prob_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"High\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-7b2aeb77c41c>\u001b[0m in \u001b[0;36mquery_gpdb\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mquery_gpdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: plpy.Error: Random forest error: Input table 'public.rf_model_output' does not exist (plpython.c:4960)\nCONTEXT:  Traceback (most recent call last):\n  PL/Python function \"forest_predict\", line 23, in <module>\n    return random_forest.forest_predict(**globals())\n  PL/Python function \"forest_predict\", line 687, in forest_predict\n  PL/Python function \"forest_predict\", line 1394, in _validate_predict\n  PL/Python function \"forest_predict\", line 602, in input_tbl_valid\nPL/Python function \"forest_predict\"\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "    DROP TABLE IF EXISTS public.credit_application_summary;\n",
    "    SELECT madlib.summary('public.credit_application_data','public.credit_application_summary');\n",
    "    SELECT * FROM public.credit_application_summary;\n",
    "\"\"\"\n",
    "data_summary = query_gpdb(query)\n",
    "\n",
    "featureNames = ['a2', 'a3', 'a8', 'a11', 'a14', 'a15', 'a1_a', 'a4_l', 'a4_u', 'a5_g', 'a5_gg', 'a6_aa', 'a6_c', 'a6_cc', 'a6_d', 'a6_e', 'a6_ff', 'a6_i', 'a6_j', 'a6_k', 'a6_m', 'a6_q', 'a6_r', 'a6_w', 'a7_bb', 'a7_dd', 'a7_ff', 'a7_h', 'a7_j', 'a7_n', 'a7_o', 'a7_v', 'a9_true', 'a10_true', 'a12_true', 'a13_g', 'a13_p']\n",
    "    \n",
    "\n",
    "def add_continuous_slider(n, default):\n",
    "    tstr = \"target_column == '{}'\".format(n)\n",
    "    minValue = math.floor(data_summary.query(tstr)['min'])\n",
    "    minValueOrZero = min(0,float(minValue))\n",
    "    maxValue = math.ceil(data_summary.query(tstr)['max'])\n",
    "    return widgets.FloatSlider(\n",
    "        value=default,\n",
    "        min=minValueOrZero,\n",
    "        max=maxValue,\n",
    "        step=0.1,\n",
    "        description=\"\",\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.1f',\n",
    "    )\n",
    "\n",
    "def add_drop_down(n, default):\n",
    "    \n",
    "    query = \"\"\"\n",
    "        SELECT {} AS col\n",
    "        FROM public.credit_application_data\n",
    "        GROUP BY 1\n",
    "        ORDER BY 1\n",
    "    \"\"\".format(n)\n",
    "    values = query_gpdb(query)['col']\n",
    "\n",
    "    return widgets.Dropdown(\n",
    "        options=values,\n",
    "        value=default,\n",
    "        description='',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "def add_widgets():\n",
    "    \n",
    "    message = \"### Loan Application \\n ------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    myWidgets = []\n",
    "\n",
    "    myWidgets.append({'a1':add_drop_down('a1','a')})\n",
    "    myWidgets.append({'a2':add_continuous_slider('a2',35.43)})\n",
    "    myWidgets.append({'a3':add_continuous_slider('a3',12.0)})\n",
    "    myWidgets.append({'a4':add_drop_down('a4','u')})\n",
    "    myWidgets.append({'a5':add_drop_down('a5','g')})\n",
    "    myWidgets.append({'a6':add_drop_down('a6','q')})\n",
    "    myWidgets.append({'a7':add_drop_down('a7','h')})\n",
    "    myWidgets.append({'a8':add_continuous_slider('a8',14.0)})\n",
    "    myWidgets.append({'a9':add_drop_down('a9',True)})\n",
    "    myWidgets.append({'a10':add_drop_down('a10',True)})\n",
    "    myWidgets.append({'a11':add_continuous_slider('a11',8.0)})\n",
    "    myWidgets.append({'a12':add_drop_down('a12',False)})\n",
    "    myWidgets.append({'a13':add_drop_down('a13','g')})\n",
    "    myWidgets.append({'a14':add_continuous_slider('a14',0.0)})\n",
    "    myWidgets.append({'a15':add_continuous_slider('a15',6590.0)})\n",
    "    \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        printmd(\"**{}:**\".format(n))\n",
    "        ipd.display(widget[n])\n",
    "\n",
    "    message = \"------\"\n",
    "    printmd(message)\n",
    "    \n",
    "    return myWidgets\n",
    "\n",
    "    \n",
    "def create_model_input(myWidgets):\n",
    "\n",
    "    checks = {}\n",
    "    conts = []\n",
    "    f = []\n",
    "    \n",
    "    for i in range(0,len(featureNames)):\n",
    "        f.append(0.0)\n",
    "    \n",
    "    for feature in featureNames:\n",
    "        if \"_\" in feature:\n",
    "            key = feature[0:feature.find(\"_\")]\n",
    "            val = feature[feature.find(\"_\")+1:len(feature)]\n",
    "            if key in checks:\n",
    "                checks[key].append(val)\n",
    "            else:\n",
    "                checks[key] = [val]\n",
    "        else:\n",
    "            conts.append(feature)\n",
    "            \n",
    "    for widget in myWidgets:\n",
    "        n = widget.keys()[0]\n",
    "        val = widget[n].value\n",
    "\n",
    "        # lower case boolean strings\n",
    "        if isinstance(val,np.bool_):\n",
    "            val = str(val).lower()\n",
    "\n",
    "        if n in checks:\n",
    "            checkFlag = False\n",
    "            for c in checks[n]:\n",
    "                if c == val:\n",
    "                    checkFlag = True\n",
    "                    pos = featureNames.index(\"{}_{}\".format(n,val))\n",
    "                    f[pos] = 1.0   \n",
    "                    \n",
    "            # make all associated values 0\n",
    "            if checkFlag == False:\n",
    "                for feature in featureNames:\n",
    "                    if \"_\" in feature and feature[0:feature.find(\"_\")+1] == n:\n",
    "                        pos = featureNames.index(feature)\n",
    "                        f[pos] = 0.0   \n",
    "        elif n in conts:\n",
    "            pos = featureNames.index(n)\n",
    "            f[pos] = val\n",
    "\n",
    "    return f\n",
    "        \n",
    "def rf_score(modelInputs):\n",
    "    \n",
    "    ddlString = \"_id integer\"\n",
    "    for f in featureNames:\n",
    "        ddlString = ddlString + \",{} float\".format(f)\n",
    "\n",
    "    query = \"\"\"\n",
    "        DROP TABLE IF EXISTS public.prod_example_data, public.prod_example_score;\n",
    "        CREATE TABLE public.prod_example_data ({});\n",
    "        INSERT INTO public.prod_example_data VALUES ({});\n",
    "        DROP TABLE IF EXISTS public.model_test_scored_tmp;\n",
    "        SELECT madlib.forest_predict('public.rf_model_output',\n",
    "                                     'public.prod_example_data',\n",
    "                                     'public.prod_example_score',\n",
    "                                     'prob');\n",
    "        SELECT * FROM public.prod_example_score;\n",
    "    \"\"\".format(ddlString, \",\".join(str(x) for x in modelInputs))\n",
    "\n",
    "    score = float(query_gpdb(query)['estimated_prob_0'])\n",
    "    \n",
    "    message = \"High\"\n",
    "    if score <= 0.33:\n",
    "        message = \"Low\"\n",
    "    elif score <= 0.66:\n",
    "        message = \"Okay\"\n",
    "    \n",
    "    return (score, message)\n",
    "    \n",
    "def on_appbutton_click(b):\n",
    "    \n",
    "    ipd.clear_output()\n",
    "    \n",
    "    message = \"### Loan Approval Results \\n------\\n\"\n",
    "    printmd(message)\n",
    "    \n",
    "    modelInput = create_model_input(myWidgets)\n",
    "    \n",
    "    s, m = rf_score(modelInput)\n",
    "    \n",
    "    message = \"**Approval Score:** {}\".format(s)\n",
    "    printmd(message)\n",
    "    \n",
    "    message = \"*Your chances of being approved are '{}'*\".format(m)\n",
    "    printmd(message)\n",
    "    \n",
    "    cleanModelInputs = \"\"\n",
    "    for i in range(0,len(featureNames)):\n",
    "        cleanModelInputs = cleanModelInputs + \"{} = {}\\n\\n\".format(featureNames[i],modelInput[i])\n",
    "\n",
    "    message = \"**Model Inputs:** \\n\\n{}\".format(cleanModelInputs)\n",
    "    printmd(message)\n",
    "    \n",
    "    printmd(\"\\n------\")\n",
    "    \n",
    "myWidgets = add_widgets()\n",
    "appbutton = widgets.Button(description=\"Calculate Approval\")\n",
    "ipd.display(appbutton)\n",
    "appbutton.on_click(on_appbutton_click)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
